{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Abhängigkeiten installieren und Packages laden"
      ],
      "metadata": {
        "id": "4_dqpQXVgm65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install gensim\n",
        "!pip install nltk\n",
        "!pip install regex\n",
        "!pip install numpy\n",
        "!pip install scikit-learn\n",
        "!pip install pyLDAvis\n",
        "!pip install matplotlib\n",
        "\n",
        "!pip install --upgrade numpy\n",
        "!pip install --upgrade scipy\n",
        "!pip install --upgrade gensim\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "import pyLDAvis.gensim_models\n",
        "import pyLDAvis\n",
        "\n",
        "# wenn es nicht läuft runtime neu starten"
      ],
      "metadata": {
        "id": "hLdud861gp-d",
        "outputId": "c43f8517-7c56-44b1-d361-2cda650cecce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (2024.11.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.13.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.2.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (3.1.6)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.10.2)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.6.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (4.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (75.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim->pyLDAvis) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->pyLDAvis) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim->pyLDAvis) (1.17.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.4\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Collecting scipy\n",
            "  Using cached scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy) (2.2.4)\n",
            "Using cached scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.4 which is incompatible.\n",
            "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scipy-1.15.2\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "Installing collected packages: numpy, scipy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.4\n",
            "    Uninstalling numpy-2.2.4:\n",
            "      Successfully uninstalled numpy-2.2.4\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.2\n",
            "    Uninstalling scipy-1.15.2:\n",
            "      Successfully uninstalled scipy-1.15.2\n",
            "Successfully installed numpy-1.26.4 scipy-1.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Subsets zusammenführen, Dopplungen entfernen"
      ],
      "metadata": {
        "id": "QHYGkuc0qYJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_data_raw = [r'/content/4_1_ergebnisse.csv', r'/content/4_2_ergebnisse.csv', r'/content/4_3_ergebnisse.csv', r'/content/4_4_ergebnisse.csv']\n",
        "\n",
        "csv_pfad = '/content/05_csv_data_raw.csv' # nicht wundern, hatte datei zwischenzeitlich umbenannt\n",
        "\n",
        "csv_no_doubles_pfad = '/content/06_data_raw_no_doubles.csv'\n",
        "\n",
        "df = pd.concat((pd.read_csv(f) for f in csv_data_raw), ignore_index=True)\n",
        "\n",
        "df.to_csv('csv_data_raw.csv', index=False)\n",
        "\n",
        "def entferne_doppelte_rezensionen(csv_pfad, anzahl_rezensionen=5):\n",
        "    df = pd.read_csv(csv_pfad)\n",
        "\n",
        "    # Doppelte Rezensionen basierend auf place_id und rezension entfernen\n",
        "    df = df.drop_duplicates(subset=['place_id', 'rezension'], keep='first')\n",
        "\n",
        "    # Anzahl der Rezensionen pro Ort begrenzen\n",
        "    df = df.groupby('place_id').head(anzahl_rezensionen).reset_index(drop=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Funktionsaufruf\n",
        "ergebnis_df = entferne_doppelte_rezensionen(csv_pfad)\n",
        "\n",
        "# Das bereinigte DataFrame anzeigen (optional)\n",
        "print(ergebnis_df)\n",
        "\n",
        "# Das bereinigte DataFrame in eine neue CSV-Datei speichern (optional)\n",
        "ergebnis_df.to_csv(\"06_data_raw_no_doubles.csv\", index=False)"
      ],
      "metadata": {
        "id": "Slx22u6-qeVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validierung der automatischen Abrufe: Zufallsstichprobe & manueller Abgleich"
      ],
      "metadata": {
        "id": "3kNZuQ7Ll3F3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(csv_no_doubles_pfad) #siehe oben\n",
        "\n",
        "def zufallsstichprobe(csv_pfad, stichprobengroesse=100, zufalls_seed=42): #seed 42\n",
        "    df = pd.read_csv(csv_no_doubles_pfad)\n",
        "\n",
        "    # Zufallsstichprobe ziehen\n",
        "    stichprobe_df = df.sample(n=min(stichprobengroesse, len(df)), random_state=zufalls_seed)\n",
        "\n",
        "    return stichprobe_df\n",
        "\n",
        "# Beispielaufruf:\n",
        "csv_datei = csv_no_doubles_pfad # Ersetzen Sie dies durch den tatsächlichen Dateinamen\n",
        "stichprobe = zufallsstichprobe(csv_datei, stichprobengroesse=100, zufalls_seed=42)\n",
        "\n",
        "# Die Stichprobe in eine neue CSV-Datei speichern (optional):\n",
        "stichprobe.to_csv(\"07_stichprobe_validierung.csv\", index=False)\n",
        "\n",
        "# Validierung manuell durchgeführt, für Kriterien siehe Hausarbeit;\n",
        "# Kodierung: 1 = valid; 0 = not valid or valid with restrictions;\n",
        "\n",
        "\n",
        "########## hier noch die Ergebnisse ausrechnen ###############"
      ],
      "metadata": {
        "id": "FijvKwsZl-Km",
        "outputId": "77c2fb07-3915-4c6e-b806-7d0bfbb8d10c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                     ort  \\\n",
            "2507   Alexius/Josef Krankenhaus, Montanusstraße 54, ...   \n",
            "11482  Sophien- und Hufeland-Klinikum gGmbH, Henry-va...   \n",
            "4207   Ev. Krankenhaus Lippstadt, Wiedenbrücker Straß...   \n",
            "1935   Rotes-Kreuz-Krankenhaus Bremen gGmbH, St.-Paul...   \n",
            "7768   Klinik Dr. Wilhelm, Hans-Urmiller-Ring 46, Wol...   \n",
            "...                                                  ...   \n",
            "10769  Hauptstandort Rudolf-Virchow-Klinikum, Virchow...   \n",
            "10563  Sana HANSE-Klinikum Wismar GmbH, Dr.-Unruh-Str...   \n",
            "8830   Bezirksklinikum Ansbach, Paracelsusstraße 36, ...   \n",
            "5006   Helios Kliniken Kassel, Hansteinstraße 29, Kassel   \n",
            "4216       LWL-Klinik Lippstadt, Im Hofholz 6, Lippstadt   \n",
            "\n",
            "                                        name                    strasze  \\\n",
            "2507               Alexius/Josef Krankenhaus             Montanusstraße   \n",
            "11482   Sophien- und Hufeland-Klinikum gGmbH  Henry-van-de-Velde-Straße   \n",
            "4207               Ev. Krankenhaus Lippstadt       Wiedenbrücker Straße   \n",
            "1935    Rotes-Kreuz-Krankenhaus Bremen gGmbH            St.-Pauli-Deich   \n",
            "7768                      Klinik Dr. Wilhelm         Hans-Urmiller-Ring   \n",
            "...                                      ...                        ...   \n",
            "10769  Hauptstandort Rudolf-Virchow-Klinikum                Virchowstr.   \n",
            "10563        Sana HANSE-Klinikum Wismar GmbH           Dr.-Unruh-Straße   \n",
            "8830                 Bezirksklinikum Ansbach           Paracelsusstraße   \n",
            "5006                  Helios Kliniken Kassel             Hansteinstraße   \n",
            "4216                    LWL-Klinik Lippstadt                 Im Hofholz   \n",
            "\n",
            "      hausnr                 stadt  bundesland                     place_id  \\\n",
            "2507      54          Grevenbroich         5.0  ChIJw7FzZxBMv0cRjlEgBW8E8q8   \n",
            "11482      2                Weimar        16.0  ChIJsXwo-S0FpEcRFkfrck38uL4   \n",
            "4207      33             Lippstadt         5.0  ChIJN-EgMv_Su0cR59EAVFIp7Og   \n",
            "1935     NaN                Bremen         4.0  ChIJh7ETvx4osUcRyTTKEulnwVw   \n",
            "7768      46        Wolfratshausen         9.0  ChIJzyXJjKPGnUcR6pbD81dI7JU   \n",
            "...      ...                   ...         ...                          ...   \n",
            "10769     18              Glauchau        14.0  ChIJ0a9ezKQvp0cR9LyxJpurJao   \n",
            "10563     14                Wismar        13.0  ChIJJzo-TVjHrUcRswybCjK0bIU   \n",
            "8830      36  Neustadt a. d. Aisch         9.0  ChIJn58c59kLokcRVMusIFGWHLw   \n",
            "5006      29                Kassel         6.0  ChIJtwosb2U_u0cRF_gesuG38XE   \n",
            "4216       6             Lippstadt         5.0  ChIJ_fI8VCTUu0cRnlWefvOgJPQ   \n",
            "\n",
            "       bewertung                                          rezension  \\\n",
            "2507           5  Bin die fünfte Woche in der Tagesklinik St. Au...   \n",
            "11482          5  Ich mußte eine OP in der Tagesklinik machen la...   \n",
            "4207           1  Leider wurde uns in der Notfallambulanz überha...   \n",
            "1935           5  Mein Vater wurde letzte Woche an der Hals-Ober...   \n",
            "7768           5  Ich war wegen einer OP durch meine Chirurgin i...   \n",
            "...          ...                                                ...   \n",
            "10769          5  Haben hier vor kurzem entbunden. Alles war top...   \n",
            "10563          1  Wer die Möglichkeit besitzt sollte dringend ei...   \n",
            "8830           5  Beste Einrichtung im Universum\\nAls Ich hier a...   \n",
            "5006           1  Mein Mann wurde morgens etwa um 10 Uhr aufgrun...   \n",
            "4216           5  Es war im Jahr 2020. Nichts ging mehr. Nicht g...   \n",
            "\n",
            "                       zeit  \n",
            "2507           vor 2 Jahren  \n",
            "11482          vor 3 Wochen  \n",
            "4207   in der letzten Woche  \n",
            "1935          vor 3 Monaten  \n",
            "7768        vor einem Monat  \n",
            "...                     ...  \n",
            "10769         vor 2 Monaten  \n",
            "10563       vor einer Woche  \n",
            "8830         vor 10 Monaten  \n",
            "5006        vor einem Monat  \n",
            "4216           vor 2 Jahren  \n",
            "\n",
            "[100 rows x 10 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "n_components bzw k festlegen"
      ],
      "metadata": {
        "id": "SNWhvh0aLyds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Daten laden und preprocessen (siehe vorherige Beispiele)\n",
        "\n",
        "# Define Parameter Grid\n",
        "param_grid = {'n_components': [2, 5, 10, 15]}\n",
        "\n",
        "# LDA Model\n",
        "lda = LatentDirichletAllocation(random_state=42)\n",
        "\n",
        "# Grid Search\n",
        "grid_search = GridSearchCV(lda, param_grid, scoring='neg_log_perplexity', cv=3)\n",
        "grid_search.fit(X)\n",
        "\n",
        "# Bestes Modell\n",
        "best_lda = grid_search.best_estimator_\n",
        "print(\"Beste Anzahl an Topics:\", grid_search.best_params_)"
      ],
      "metadata": {
        "id": "WINmnHnxL011",
        "outputId": "91fd697f-51b1-40ab-cb98-308e58b0bd2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3257cd2b60cb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Grid Search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_log_perplexity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Bestes Modell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LDA Analysis und erste Visualisierung"
      ],
      "metadata": {
        "id": "a-6XLHZ_Kin-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim # LDA\n",
        "!pip install pyLDAvis # Visualisierung\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "import pyLDAvis.gensim_models  # Wichtig: gensim_models importieren\n",
        "import pyLDAvis\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', str(text))\n",
        "    text = text.lower()\n",
        "    tokens = text.split()\n",
        "    stop_words = set(stopwords.words('german'))\n",
        "    tokens = [token for token in tokens if token not in stop_words and len(token) > 2]\n",
        "    return tokens\n",
        "\n",
        "def prepare_corpus(processed_docs):\n",
        "    dictionary = corpora.Dictionary(processed_docs)\n",
        "    corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "    return dictionary, corpus\n",
        "\n",
        "def train_lda(corpus, dictionary, num_topics=5):\n",
        "    lda_model = LdaModel(corpus, num_topics=num_topics, id2word=dictionary, random_state=42)\n",
        "    return lda_model\n",
        "\n",
        "def evaluate_model(lda_model, corpus, dictionary, processed_docs):\n",
        "    coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_docs, dictionary=dictionary, coherence='c_v')\n",
        "    coherence = coherence_model_lda.get_coherence()\n",
        "    print('\\nCoherence Score: ', coherence)\n",
        "    return coherence\n",
        "\n",
        "def display_topics(lda_model, num_words=10):\n",
        "    for idx, topic in lda_model.print_topics(-1, num_words=num_words):\n",
        "        print(f'Topic: {idx} \\nWords: {topic}')\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(r'/content/06_data_raw_no_doubles.csv')\n",
        "review_column = 'rezension'\n",
        "if review_column not in df.columns:\n",
        "    raise ValueError(f\"Column '{review_column}' not found in DataFrame.\")\n",
        "\n",
        "# Preprocess data\n",
        "processed_docs = df[review_column].astype(str).map(preprocess_text)\n",
        "\n",
        "# Prepare corpus\n",
        "dictionary, corpus = prepare_corpus(processed_docs)\n",
        "\n",
        "# Train LDA model\n",
        "num_topics = 5  # Adjust as needed\n",
        "lda_model = train_lda(corpus, dictionary, num_topics)\n",
        "\n",
        "# Evaluate model\n",
        "coherence_score = evaluate_model(lda_model, corpus, dictionary, processed_docs)\n",
        "\n",
        "# Display topics\n",
        "display_topics(lda_model)\n",
        "\n",
        "# Visualisierung mit pyLDAvis\n",
        "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary) # prepare aus gensim_models\n",
        "pyLDAvis.display(vis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ir2eUyMp2yJR",
        "outputId": "77517c43-d4f7-4f01-826b-51f75c37213e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.13.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.2.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (3.1.6)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.10.2)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.6.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (4.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (75.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim->pyLDAvis) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->pyLDAvis) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim->pyLDAvis) (1.17.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Coherence Score:  0.3598509036866703\n",
            "Topic: 0 \n",
            "Words: 0.021*\"gut\" + 0.013*\"dank\" + 0.013*\"freundlich\" + 0.012*\"team\" + 0.011*\"station\" + 0.010*\"wurde\" + 0.009*\"ärzte\" + 0.009*\"klinik\" + 0.009*\"super\" + 0.009*\"vielen\"\n",
            "Topic: 1 \n",
            "Words: 0.019*\"wurde\" + 0.007*\"krankenhaus\" + 0.007*\"mal\" + 0.006*\"patienten\" + 0.006*\"arzt\" + 0.006*\"mehr\" + 0.006*\"notaufnahme\" + 0.005*\"leider\" + 0.005*\"gut\" + 0.005*\"schon\"\n",
            "Topic: 2 \n",
            "Words: 0.021*\"klinik\" + 0.008*\"wurde\" + 0.007*\"essen\" + 0.006*\"gut\" + 0.006*\"gibt\" + 0.005*\"immer\" + 0.004*\"freundlich\" + 0.004*\"zimmer\" + 0.004*\"schon\" + 0.004*\"wochen\"\n",
            "Topic: 3 \n",
            "Words: 0.010*\"wurde\" + 0.009*\"krankenhaus\" + 0.006*\"notaufnahme\" + 0.006*\"freundlich\" + 0.006*\"arzt\" + 0.006*\"klinik\" + 0.005*\"mal\" + 0.005*\"schmerzen\" + 0.005*\"wirklich\" + 0.004*\"super\"\n",
            "Topic: 4 \n",
            "Words: 0.013*\"klinik\" + 0.012*\"patienten\" + 0.009*\"immer\" + 0.006*\"gut\" + 0.005*\"therapeuten\" + 0.005*\"mal\" + 0.005*\"wurde\" + 0.005*\"personal\" + 0.005*\"zeit\" + 0.004*\"mehr\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el50031379722601265284183371677\" style=\"background-color:white;\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el50031379722601265284183371677_data = {\"mdsDat\": {\"x\": [0.09597229810668541, -0.11550871660903002, -0.01394544183646202, -0.01451533042088759, 0.047997190759694386], \"y\": [0.020918493078072305, 0.05398549282581338, -0.061063767502731986, -0.06464192207578005, 0.050801703674626324], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [34.10348108136901, 29.29901008410529, 18.63213280049126, 10.186994875473227, 7.778381158561225]}, \"tinfo\": {\"Term\": [\"klinik\", \"freundlich\", \"team\", \"gut\", \"dank\", \"krankenhaus\", \"notaufnahme\", \"wurde\", \"arzt\", \"schmerzen\", \"patienten\", \"aufgehoben\", \"super\", \"essen\", \"station\", \"mal\", \"stunden\", \"kompetent\", \"vielen\", \"gef\\u00fchlt\", \"warten\", \"schwestern\", \"gibt\", \"immer\", \"therapeuten\", \"mehr\", \"konnte\", \"wirklich\", \"betreuung\", \"danke\", \"nan\", \"weiterbehandlung\", \"warteraum\", \"spritze\", \"kr\\u00fccken\", \"behandlungszimmer\", \"bet\\u00e4ubung\", \"krankenbett\", \"flasche\", \"gesundheitlich\", \"narben\", \"starten\", \"taxi\", \"schwanger\", \"r\\u00f6ntgenbilder\", \"scheiben\", \"abszess\", \"wohlgemerkt\", \"sch\\u00e4mt\", \"betracht\", \"feste\", \"kritisch\", \"vernachl\\u00e4ssigt\", \"geburtsstation\", \"betteln\", \"schande\", \"fehldiagnosen\", \"behutsam\", \"tasche\", \"schwarz\", \"vormittag\", \"fuhr\", \"frechheit\", \"sterben\", \"vati\", \"daraufhin\", \"blutdruck\", \"gesagt\", \"ultraschall\", \"stunden\", \"sagten\", \"w\\u00fctend\", \"termin\", \"sagte\", \"meinte\", \"uhr\", \"geld\", \"wartezimmer\", \"gewartet\", \"info\", \"\\u00fcberweisung\", \"erst\", \"niemand\", \"nachfrage\", \"antwort\", \"katastrophe\", \"kam\", \"warten\", \"sei\", \"solle\", \"stunde\", \"entt\\u00e4uscht\", \"unfreundlich\", \"geschickt\", \"gefragt\", \"wurde\", \"arzt\", \"stern\", \"minuten\", \"obwohl\", \"hause\", \"sp\\u00e4ter\", \"notaufnahme\", \"mutter\", \"warum\", \"mal\", \"leider\", \"w\\u00e4re\", \"mehr\", \"krankenhaus\", \"bekommen\", \"h\\u00e4tte\", \"wegen\", \"schmerzen\", \"tag\", \"geht\", \"schon\", \"patienten\", \"wurden\", \"einfach\", \"gehen\", \"\\u00e4rztin\", \"personal\", \"gut\", \"\\u00e4rzte\", \"klinik\", \"immer\", \"zimmer\", \"station\", \"zeit\", \"menschen\", \"essens\", \"handchirurgie\", \"praxisteam\", \"gro\\u00dfk\\u00fcche\", \"belange\", \"schmackhaftes\", \"becker\", \"anna\", \"beginnend\", \"wundversorgung\", \"angenehmen\", \"vorbereitungen\", \"bed\\u00fcrfnissen\", \"organisiertes\", \"bauer\", \"umsichtig\", \"modernisiert\", \"rettungssanit\\u00e4ter\", \"endet\", \"angstpatientin\", \"katja\", \"jahrzehnte\", \"christina\", \"eingespieltes\", \"eingespielt\", \"unkomplizierte\", \"zuvorkommende\", \"its\", \"hilfestellungen\", \"vorgestern\", \"apotheke\", \"hoffmann\", \"rundum\", \"angenehme\", \"potsdam\", \"frauenklinik\", \"aufgehoben\", \"beeindruckt\", \"herzlichen\", \"team\", \"strukturiert\", \"freundliches\", \"betreut\", \"tolles\", \"reibungslos\", \"betreuung\", \"kompetente\", \"dank\", \"kompetent\", \"gef\\u00fchlt\", \"dankesch\\u00f6n\", \"gesamte\", \"bestens\", \"uneingeschr\\u00e4nkt\", \"gro\\u00dfes\", \"hilfsbereit\", \"lob\", \"hebammen\", \"vielen\", \"gut\", \"herzlich\", \"jederzeit\", \"freundlich\", \"weiterempfehlen\", \"gesamten\", \"danke\", \"hervorragend\", \"super\", \"bedanken\", \"station\", \"f\\u00fchlte\", \"schwestern\", \"\\u00e4rzte\", \"gute\", \"zufrieden\", \"personal\", \"empfehlen\", \"zeit\", \"aufenthalt\", \"wirklich\", \"essen\", \"immer\", \"krankenhaus\", \"klinik\", \"wurde\", \"nett\", \"m\\u00f6chte\", \"behandlung\", \"and\", \"bester\", \"therapeutenteam\", \"werdet\", \"kritischen\", \"geburtenstation\", \"erkenntnisse\", \"ansehen\", \"verlegen\", \"segen\", \"wut\", \"\\u00fcberlebt\", \"beigebracht\", \"cannabis\", \"schnitt\", \"sozialarbeiterin\", \"l\\u00f6sungsorientiert\", \"lockere\", \"unterschrift\", \"ehrliche\", \"erfahrene\", \"profis\", \"unn\\u00f6tigen\", \"betreuten\", \"werk\", \"engmaschig\", \"christian\", \"prinzip\", \"besitzen\", \"unangenehmes\", \"h\\u00f6chste\", \"vergabe\", \"bereue\", \"erzielen\", \"einzulassen\", \"psychiatrischen\", \"meistern\", \"grenzen\", \"ausgezeichnete\", \"opfer\", \"anstrengend\", \"erm\\u00f6glichen\", \"themen\", \"therapien\", \"tagesklinik\", \"gruppe\", \"therapie\", \"mitpatienten\", \"therapeuten\", \"gef\\u00fchle\", \"psychologen\", \"ergotherapie\", \"lernen\", \"patienten\", \"gespr\\u00e4che\", \"psychische\", \"konzept\", \"leben\", \"arbeiten\", \"offenes\", \"helfen\", \"immer\", \"klinik\", \"menschen\", \"ohr\", \"depressionen\", \"probleme\", \"einrichtung\", \"geholfen\", \"wochen\", \"gibt\", \"einfach\", \"sagen\", \"wer\", \"mal\", \"mehr\", \"m\\u00f6chte\", \"hilfe\", \"zeit\", \"personal\", \"geben\", \"gut\", \"schon\", \"daf\\u00fcr\", \"tag\", \"viele\", \"empfehlen\", \"wirklich\", \"\\u00e4rzte\", \"wurde\", \"geht\", \"vielen\", \"dank\", \"psychosomatische\", \"abgefertigt\", \"schlie\\u00dfung\", \"kr\\u00e4ften\", \"arthroskopie\", \"k\\u00fchlschrank\", \"aufrecht\", \"koordination\", \"vermisse\", \"mitarbeit\", \"mobil\", \"mental\", \"hilfsbereiten\", \"sensationell\", \"bestm\\u00f6glich\", \"schichten\", \"jessica\", \"erfahrenen\", \"fahrl\\u00e4ssigkeit\", \"angeleitet\", \"bistro\", \"kenntnis\", \"ausgesetzt\", \"studium\", \"abgeht\", \"schulmedizin\", \"website\", \"feine\", \"autounfall\", \"abwechslungsreiche\", \"gesammelt\", \"geborgenheit\", \"besitzt\", \"tep\", \"gro\\u00dfem\", \"organisierte\", \"fahrrad\", \"balkon\", \"\\u00fcberlastung\", \"herzzentrum\", \"hierzu\", \"hallux\", \"bestellen\", \"wald\", \"gelegenheit\", \"klinik\", \"anwendungen\", \"pro\", \"kuchen\", \"schwimmbad\", \"klinikpersonal\", \"gel\\u00e4nde\", \"auswahl\", \"gibt\", \"reha\", \"essen\", \"wlan\", \"rehaklinik\", \"zimmer\", \"wochen\", \"wurde\", \"konnte\", \"mittagessen\", \"immer\", \"gab\", \"schon\", \"gut\", \"mehr\", \"jedoch\", \"leider\", \"freundlich\", \"woche\", \"fr\\u00fchst\\u00fcck\", \"tag\", \"station\", \"therapeuten\", \"therapie\", \"wurden\", \"patienten\", \"zufrieden\", \"aufenthalt\", \"zeit\", \"personal\", \"team\", \"nat\\u00fcrlich\", \"m\\u00f6chte\", \"krankenhaus\", \"super\", \"mal\", \"blieben\", \"derma\\u00dfen\", \"arme\", \"johannes\", \"wolf\", \"zeitweise\", \"operativen\", \"\\u00e4rzteschaft\", \"sympathischen\", \"unh\\u00f6fliche\", \"ibuprofen\", \"sprunggelenk\", \"fraktur\", \"knappe\", \"verwandte\", \"aufwand\", \"schlauch\", \"freunden\", \"drinnen\", \"sch\\u00f6nem\", \"gips\", \"gest\\u00fcrzt\", \"diskriminierung\", \"erstaufnahme\", \"f\\u00f6rmlich\", \"verdammt\", \"nachtwache\", \"angelegenheiten\", \"versprochene\", \"daniel\", \"vertrauensvoll\", \"z\\u00e4hne\", \"schlucken\", \"k\\u00fcnstliche\", \"weiterempfehlung\", \"bruch\", \"restliche\", \"nase\", \"aufregung\", \"clinic\", \"wars\", \"notfallambulanz\", \"zahnarzt\", \"schmerzen\", \"infusion\", \"starken\", \"retten\", \"privatpatient\", \"notaufnahme\", \"krankenhaus\", \"arzt\", \"operiert\", \"erkl\\u00e4rt\", \"wurde\", \"warten\", \"mal\", \"nie\", \"konnte\", \"freundlich\", \"wirklich\", \"schwestern\", \"super\", \"schon\", \"mehr\", \"lassen\", \"klinik\", \"leider\", \"station\", \"zeit\", \"tag\", \"stunden\", \"ganz\", \"nett\", \"schwester\", \"empfehlen\", \"heute\", \"personal\", \"\\u00e4rzte\", \"immer\", \"gut\", \"aufenthalt\", \"essen\", \"patienten\"], \"Freq\": [5078.0, 3302.0, 2558.0, 5479.0, 2875.0, 3287.0, 1894.0, 6752.0, 1826.0, 854.0, 3313.0, 1471.0, 2291.0, 2109.0, 3130.0, 2421.0, 855.0, 1266.0, 2048.0, 1454.0, 692.0, 1952.0, 1673.0, 3349.0, 1072.0, 2195.0, 1341.0, 2045.0, 1062.0, 1727.0, 192.9036510990349, 37.25426126181201, 33.156317883089116, 35.50991670339222, 34.89293750055703, 24.59052198019272, 21.059032514836023, 20.892557949501352, 36.60344264196387, 28.79327958476059, 18.754085511835914, 19.430889162788638, 35.625061471893915, 26.063730854370647, 17.099695455008458, 21.473202092237702, 21.728672152981673, 17.280655328538824, 17.130401747321827, 16.47095624747014, 18.77861881079405, 15.87328661325212, 16.65784692701779, 34.65467805150133, 21.264920981600262, 37.00781476722858, 21.930195680137793, 13.796705567364311, 27.744650167872454, 13.564825110089224, 28.268994105822827, 25.072677997377113, 116.399688639024, 73.90072695329341, 50.02474670045488, 102.04018423846279, 95.00147414926954, 531.8152001926703, 72.61055881511848, 704.5060630921058, 39.314807835669995, 37.59695912877449, 703.548181549124, 319.7553435204015, 189.4286024184707, 612.6346403686088, 167.50648382524167, 88.09493153629715, 133.29062417624414, 67.3889162960303, 72.84753494965929, 517.6933734348012, 228.03500115558543, 122.9761605317574, 189.51801687013702, 190.00555390024394, 773.9379103128614, 518.4651660218369, 375.5340159685597, 143.59260542965762, 226.31924583809382, 151.84092713765097, 302.3374306059011, 183.8644067880703, 179.55759214105888, 3688.115635700547, 1144.4478807924754, 334.1044366491933, 266.79628843848826, 451.7932077590153, 461.21047588313303, 318.71020772545734, 1106.7451359047416, 632.1491718515092, 281.9495994199761, 1263.506329865145, 985.0441167611563, 507.7486602613023, 1110.004676827205, 1414.328444466101, 534.1888365354857, 517.3887630064346, 545.7401147259731, 497.5139458450639, 707.3116057551247, 693.6154051492473, 861.704641817323, 1186.783430051627, 676.7256276572293, 770.1494099742141, 523.5340634922659, 463.62713805922846, 730.1978749244971, 894.2216602898104, 719.6249222288296, 819.5176786656477, 718.5351571534025, 559.9573465924196, 618.8951663520544, 571.1862873549074, 537.5893026510112, 28.24513113844545, 22.630958961734954, 21.850705676499032, 19.77931040893138, 25.89908587263568, 13.757144033552182, 13.814827947106698, 29.371951873135078, 15.153307832087382, 15.61762273899017, 66.99478287057688, 12.05491433310969, 12.145189615969715, 12.888966396736905, 13.182017275216527, 25.782790109273442, 10.537644091384106, 11.61438975063666, 10.060468418497802, 11.659345631357281, 11.710426369666706, 10.451359173571687, 16.27651009370717, 24.439205379105996, 10.034431196877618, 9.576996889460572, 13.545584134174804, 52.26911374330206, 12.603622411494268, 12.148741124567673, 26.965629016279554, 16.80399641347627, 282.2713778485111, 80.69224601435953, 21.15702788705173, 29.754206602924636, 1229.4109178574556, 126.92552186787147, 313.7677536761785, 2048.2056431497235, 48.5627641536492, 271.3198359227855, 560.1882665503891, 224.15788720687894, 131.71674373375726, 845.2283957186921, 276.84612679650576, 2181.3868807508056, 989.7647414184652, 1123.026948632404, 477.7778843819272, 789.847859103455, 316.50007632326725, 144.77127619983676, 514.4649634156613, 816.0056359057306, 404.901827189014, 263.77290167641837, 1432.971891935976, 3512.316397164349, 450.344644850093, 453.9956243878537, 2175.150996067625, 395.46021930796064, 383.89484276756406, 1171.9476713704914, 280.5026739517856, 1433.6494958605836, 449.3462619724706, 1845.31079337206, 465.92804276498146, 1144.9302238109176, 1558.468669398154, 731.777876235839, 635.4877871133712, 1350.5327341773113, 866.9005478056861, 1128.8885210504777, 732.9258386109367, 953.3519105961419, 946.39587084965, 1221.3750281701218, 1201.8376269158596, 1483.0016228592326, 1636.743784968214, 715.4075501128211, 744.271380356502, 695.5243825911793, 26.103862875240786, 23.80574506258975, 35.01018591810005, 24.628675527675682, 20.39381406576718, 21.212917987154675, 20.059566386239, 17.254364614656847, 17.35789269736603, 16.097449582944094, 15.708409021927999, 19.406860843032067, 16.781156821997186, 15.077915986954642, 16.45817737071293, 64.9917945665599, 13.56413012884795, 12.966246363921568, 12.805648636641576, 19.738188425620265, 12.629157673412193, 12.286297228794883, 11.147661699749666, 11.367401275809177, 15.2182159987341, 11.52385307378792, 10.70819775646887, 12.15315525672794, 11.094628480844856, 12.68403040130081, 17.300839782517276, 15.118581378611562, 30.00607966917045, 27.27849620349042, 19.180583747859785, 35.591887479150685, 20.896026633813523, 30.64681281492345, 44.15207865628956, 21.723197322997724, 38.70266674931538, 18.03711637090919, 53.98656363682559, 332.97135382399745, 367.0181754274557, 116.61562868328585, 370.9947634403256, 115.20368881038021, 537.7385769218189, 33.806427664641724, 119.96085523651949, 72.09580640215238, 77.0394392685155, 1301.4556691038072, 129.85947284609992, 55.806514054670465, 91.22224060238135, 290.95424929355937, 211.72557076439102, 142.55237988583312, 237.93777227787285, 975.9995741011165, 1316.7250506761116, 429.42483250718914, 140.86062172365354, 62.060078074169134, 194.47660680818933, 186.5255235185899, 333.2135271968868, 417.2166858936344, 442.82661741324455, 430.22547441985034, 327.0781115162869, 183.4891093838301, 511.35895651711127, 465.1292958069115, 376.2329793361154, 282.462510055522, 471.9999918969993, 490.65065105267547, 220.66661558492729, 608.2947378782236, 365.80791691653826, 247.1939442265157, 309.389283624359, 231.21055028410294, 308.7832661727477, 335.9712667470074, 377.7782216343313, 497.34088515187227, 290.0854717856319, 296.87871230438657, 290.695845048512, 23.72324273217006, 20.423765837336077, 18.397477590299225, 18.428709974670063, 16.170538735875468, 18.99284699620117, 14.45454206557676, 13.944241825028232, 26.022651361958232, 13.148440504952628, 15.735838161393477, 12.18528649015641, 29.259957850778633, 11.87416836948683, 13.918055183691532, 12.294287178997385, 11.139719226824678, 10.291791589415347, 10.030943804132857, 9.769439939210628, 13.612969004348525, 10.952849618004809, 9.068519875424965, 9.284401675158001, 10.183479410006187, 12.583004628672128, 15.73973472564166, 8.978543001537025, 8.437407017920771, 22.18216570807692, 19.505696717326934, 15.957849191829322, 14.456160229048157, 25.74978875447728, 23.145106018858673, 15.453133527783312, 23.136251854088155, 47.593284323148104, 15.343166597445027, 22.139039073811496, 16.017614804030323, 15.481001529109303, 22.63058990533996, 46.95467020527625, 24.99511589455519, 1210.8904118585062, 79.3746136052292, 58.3536157277795, 35.82500504552899, 31.409135052997296, 34.35022782097408, 39.75908474241468, 67.51702434329258, 327.3419174393791, 171.13299068039933, 375.35421463297456, 56.85590481949328, 42.67695112699832, 207.7032057388286, 205.87974006371476, 473.9820265944087, 186.00901194368768, 61.69234098635959, 301.85639822901516, 124.53513799356297, 206.30661591144144, 334.5341601390572, 204.88549253058045, 90.38685298246016, 177.23789404994943, 228.3833814691312, 109.49978167799553, 62.24446568029162, 145.00049878113862, 195.05341818986957, 124.9739347002444, 98.49984899109175, 133.74177967958215, 187.99376843700287, 115.64449220155522, 128.71645909912147, 156.45843991616428, 143.75884020657296, 135.85372748049485, 92.5221834949945, 113.46784447084681, 129.22280290503642, 118.7773764229496, 117.96775585378298, 19.77814539474437, 22.751052710539167, 17.0160650526957, 12.989924462215487, 13.13103535895131, 12.001937389837252, 13.051532542072541, 11.82432209307565, 15.036285165187735, 12.654122585441664, 10.079693805698959, 20.02094213142399, 26.308125665554027, 9.172144795290077, 14.503581498188938, 14.083792961474773, 10.419471585227184, 8.09615515991791, 7.7924563804082085, 7.857959092570513, 9.430924508660288, 28.57260228568034, 8.258204625966185, 9.588940928669608, 6.67585310792523, 11.325068835005753, 6.6075224381027375, 7.3263665449936575, 6.638842672368429, 10.606430443939239, 15.080361685342702, 17.0491789511711, 19.11459757446849, 10.606034250499643, 19.145769871119718, 36.998448165551395, 14.18409466408152, 24.338597283295584, 14.615316937110158, 12.934386269029156, 18.16496761438645, 26.58242866963684, 21.627105256139846, 225.28345266978405, 27.11463328528384, 65.56168403196746, 14.597343469340831, 23.338988536689225, 274.7320104662517, 383.67701835717924, 251.8636438623678, 118.44554371390979, 91.31896113289969, 456.28005537375543, 119.52457146724423, 239.30802995024857, 137.68923812699867, 169.20264717091123, 272.31862352597295, 198.3082261415055, 179.98360907902216, 192.99517052847244, 176.57049402616482, 179.90583325918777, 103.55990602472505, 248.33622192278418, 150.39116932400228, 190.9267969624381, 165.68226528398503, 128.0373157748665, 101.57660230133607, 123.56682138456645, 124.2138255890377, 98.7319435638487, 124.48025043895625, 99.12070075734688, 139.6561861724967, 130.32222429384885, 131.50967698515254, 129.8696393213513, 108.13204942929663, 110.35534478901886, 112.7266742718637], \"Total\": [5078.0, 3302.0, 2558.0, 5479.0, 2875.0, 3287.0, 1894.0, 6752.0, 1826.0, 854.0, 3313.0, 1471.0, 2291.0, 2109.0, 3130.0, 2421.0, 855.0, 1266.0, 2048.0, 1454.0, 692.0, 1952.0, 1673.0, 3349.0, 1072.0, 2195.0, 1341.0, 2045.0, 1062.0, 1727.0, 193.91464881283716, 38.12781606686186, 33.98151183193899, 36.76852855709532, 36.2178146674733, 25.527453666404202, 21.88340385228192, 21.71467737919996, 38.1372936986356, 30.00920044600911, 19.550556793530305, 20.260517749546743, 37.15209474255041, 27.19851767427564, 17.850773330622268, 22.434760317535613, 22.710878747570863, 18.062597115993846, 17.922645770098516, 17.243324250335448, 19.66748454471636, 16.6400877033585, 17.49904766876675, 36.426159916047844, 22.39464343775703, 38.97548182188206, 23.108317318150274, 14.560533440538942, 29.33412858717038, 14.344417679749093, 29.92607923542638, 26.619641938828504, 126.06658465799127, 80.13199966960657, 54.1157154179009, 112.91968916828483, 105.1880323587316, 636.8214216635581, 80.12436059315007, 855.2894584607753, 42.35950368222416, 40.435526244318815, 858.8999477556666, 376.37292429713017, 219.33975134997385, 775.7780700125107, 196.0611628344493, 99.29438181729716, 154.27029464693842, 74.78067136745972, 81.48315801734739, 662.7990139471351, 279.8392582321588, 144.09071369136657, 229.98076367742726, 231.41359553050873, 1069.9293891178697, 692.011182636251, 487.9051505646633, 171.0055795643261, 283.6087719592035, 184.07117772617494, 398.39504097865677, 228.81449524752233, 224.31803237481444, 6752.462387788798, 1826.9137612707812, 452.2513240517567, 351.6147484183903, 645.4417102538739, 664.5791606985684, 434.39622583654216, 1894.5740169214962, 999.2560654044756, 384.45217772267495, 2421.3723737206597, 1820.4000718445202, 804.813931211441, 2195.715622306572, 3287.0344984771837, 915.9616058289635, 880.5768643750337, 962.1570388877258, 854.7085965837748, 1423.4858008903159, 1401.8425743287187, 1964.6611892879862, 3313.88638385459, 1380.3410067528894, 1691.8555956582222, 962.6312003219555, 801.2488768307448, 2854.796286533554, 5479.236594792792, 2860.5250767646576, 5078.470985982282, 3349.2758346388086, 1452.2216574552758, 3130.5143617443687, 2494.215505502534, 1221.5468738658749, 29.01359359230858, 23.492126617889713, 22.721636901724228, 20.601076227990024, 27.11157070037728, 14.505611698453208, 14.582515708723378, 31.020640562803486, 16.012731092428183, 16.542256948576266, 71.25147182064963, 12.829394774453696, 12.959971096201405, 13.783771177172184, 14.097455100567329, 27.58115781933756, 11.287086168245173, 12.467265221836586, 10.828339592342704, 12.55221819681027, 12.609095257977588, 11.258887218506342, 17.535981215449823, 26.358367256808826, 10.822763020776556, 10.330817645086928, 14.619868869604215, 56.44753304239198, 13.626350194493268, 13.155488679290212, 29.265332172816986, 18.19988509135144, 315.8284403237519, 88.97221930842171, 23.044015320826045, 32.66626453391519, 1471.608623509168, 143.79380973616912, 369.6138622265306, 2558.5650569339678, 54.07883566148963, 319.5409892844818, 684.2166630050574, 263.63748436370673, 152.6423781349807, 1062.7160625296165, 334.56690059918145, 2875.7372692922277, 1266.4705767866053, 1454.951971191808, 596.2427590964529, 1025.8088669170106, 395.6698326291093, 172.96022041986785, 669.9615088956242, 1107.929732229871, 522.4491658937054, 331.98679406503527, 2048.664520477651, 5479.236594792792, 592.6598412386821, 599.5471980868435, 3302.0204948409846, 517.1114676330967, 503.4944088644857, 1727.7985486364548, 358.41128816426504, 2291.3451569168724, 613.842875068338, 3130.5143617443687, 649.0730498290865, 1952.4322458909405, 2860.5250767646576, 1166.9753958959645, 977.2662399122945, 2854.796286533554, 1612.720914209509, 2494.215505502534, 1340.5079627867028, 2045.298043594744, 2109.8629945271487, 3349.2758346388086, 3287.0344984771837, 5078.470985982282, 6752.462387788798, 1418.6962321372087, 1557.8796785764814, 1545.493158412151, 26.879764444042856, 24.586279622021607, 36.194055040584765, 25.518377922263962, 21.173306016099374, 22.028261250706848, 20.876156119121383, 18.042876756936778, 18.169760318395927, 16.86756938727746, 16.47053784682964, 20.34850231450993, 17.607101929185365, 15.853757810025812, 17.37754103015982, 68.70272456563765, 14.383814157961117, 13.773530648165194, 13.610874012829107, 21.02632044465173, 13.479048607637813, 13.136034897793854, 11.92006868654154, 12.155291639184131, 16.283121917367392, 12.339912401755091, 11.486441980589, 13.041033716738896, 11.907492800612665, 13.614856978263717, 18.594618842954567, 16.268920798061657, 32.64301295941388, 29.716280837406753, 20.853176760781416, 39.69554697574446, 22.929420422797907, 34.36144364108628, 50.51890746893252, 23.960292669572542, 45.011097245905894, 19.688135178841527, 66.21000480112191, 508.4827611416958, 582.7379320858219, 163.5006322758996, 633.9174651642481, 166.4652056967745, 1072.42117462058, 40.69318227585569, 186.34331961469042, 100.98984268112267, 109.74616083805834, 3313.88638385459, 206.43079867293665, 74.94160768184989, 139.0143298383994, 624.0441993077565, 420.1906839413155, 254.45614207737228, 510.86667408892475, 3349.2758346388086, 5078.470985982282, 1221.5468738658749, 272.397468540434, 89.56232562469711, 439.0976265621585, 419.15186051337486, 950.9303210428931, 1430.5841840549947, 1673.009639911517, 1691.8555956582222, 1136.524305687392, 472.5669587449754, 2421.3723737206597, 2195.715622306572, 1557.8796785764814, 967.3090231630256, 2494.215505502534, 2854.796286533554, 653.7987696657805, 5479.236594792792, 1964.6611892879862, 848.5118607005795, 1423.4858008903159, 789.3090875119029, 1612.720914209509, 2045.298043594744, 2860.5250767646576, 6752.462387788798, 1401.8425743287187, 2048.664520477651, 2875.7372692922277, 24.58545883408621, 21.231225137813347, 19.184078782669083, 19.234586302390557, 16.99202306953691, 20.003112973705864, 15.274414754561999, 14.809359278012257, 27.797399176838987, 14.065907593037894, 16.83924443278598, 13.077559459087482, 31.427653692603148, 12.763029058180603, 15.010418492560884, 13.263868744448997, 12.034821552424322, 11.141786391205617, 10.89487351568946, 10.61446437811029, 14.802225800565965, 11.917384890440472, 9.877123586724547, 10.117247945234908, 11.12061459768273, 13.741489027515597, 17.194884891988917, 9.818590237372737, 9.24438236980311, 24.33766753527316, 21.47704333260164, 17.58295969165842, 15.968753346115104, 28.964330763671487, 26.095435393652654, 17.132485071114488, 26.780576229297147, 59.21330861176801, 17.272405663229975, 26.0979904895658, 18.176653866726877, 17.650999510274072, 28.644260015495632, 73.9681356563329, 32.880545111473815, 5078.470985982282, 153.79128704009216, 102.83345847021202, 54.09613695002841, 46.01224248495476, 52.15165679447497, 69.67963766017786, 154.6168571878902, 1673.009639911517, 638.1523042817081, 2109.8629945271487, 125.62564183815881, 80.08030563680772, 1452.2216574552758, 1430.5841840549947, 6752.462387788798, 1341.1525700149828, 175.9823790016633, 3349.2758346388086, 676.6703385205708, 1964.6611892879862, 5479.236594792792, 2195.715622306572, 436.34258321819226, 1820.4000718445202, 3302.0204948409846, 681.8632583075932, 201.04882707563976, 1423.4858008903159, 3130.5143617443687, 1072.42117462058, 633.9174651642481, 1380.3410067528894, 3313.88638385459, 977.2662399122945, 1340.5079627867028, 2494.215505502534, 2854.796286533554, 2558.5650569339678, 605.9732424211783, 1557.8796785764814, 3287.0344984771837, 2291.3451569168724, 2421.3723737206597, 20.635619613916912, 23.78449017126703, 17.992498448502396, 13.884711439917407, 14.045010295596375, 12.843431158580213, 14.010300112436207, 12.707299434254235, 16.17199847303576, 13.649858279767383, 10.903296954861808, 21.667070515934924, 28.57430856855109, 9.988918562567136, 15.903086589291917, 15.44743766296447, 11.44021684422198, 8.931337704037565, 8.628251487598465, 8.720181712719647, 10.507032262671984, 31.847342354748633, 9.208088556384247, 10.730048304288498, 7.499799890251818, 12.725945690322066, 7.42882406042735, 8.249464487706394, 7.479769925811645, 11.959837946117629, 17.012885665169698, 19.48547091800771, 21.934346395268896, 12.061839779315163, 22.372553322029063, 46.66094094869432, 16.943557466556392, 31.67453996381504, 17.808242520557243, 15.460770770690774, 24.13313099583327, 39.775698350792666, 31.770782060591255, 854.7085965837748, 43.75614703846595, 172.85133773783224, 18.586360406535086, 38.32688460638592, 1894.5740169214962, 3287.0344984771837, 1826.9137612707812, 590.7062760395938, 396.5624540344658, 6752.462387788798, 692.011182636251, 2421.3723737206597, 920.478524400562, 1341.1525700149828, 3302.0204948409846, 2045.298043594744, 1952.4322458909405, 2291.3451569168724, 1964.6611892879862, 2195.715622306572, 722.4528603011556, 5078.470985982282, 1820.4000718445202, 3130.5143617443687, 2494.215505502534, 1423.4858008903159, 855.2894584607753, 1360.0714772111746, 1418.6962321372087, 811.3802415924489, 1612.720914209509, 934.8258681648022, 2854.796286533554, 2860.5250767646576, 3349.2758346388086, 5479.236594792792, 1340.5079627867028, 2109.8629945271487, 3313.88638385459], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.8994, -8.5438, -8.6604, -8.5918, -8.6093, -8.9592, -9.1143, -9.1222, -8.5614, -8.8014, -9.2302, -9.1947, -8.5885, -8.901, -9.3225, -9.0948, -9.083, -9.312, -9.3207, -9.36, -9.2289, -9.397, -9.3487, -8.6162, -9.1045, -8.5505, -9.0737, -9.5372, -8.8385, -9.5541, -8.8198, -8.9398, -7.4046, -7.8589, -8.2491, -7.5362, -7.6077, -5.8853, -7.8765, -5.6041, -8.49, -8.5347, -5.6055, -6.394, -6.9176, -5.7438, -7.0406, -7.6832, -7.2691, -7.9511, -7.8732, -5.9122, -6.7321, -7.3496, -6.9171, -6.9145, -5.5101, -5.9107, -6.2332, -7.1946, -6.7396, -7.1388, -6.45, -6.9474, -6.9711, -3.9487, -5.1189, -6.3501, -6.5751, -6.0484, -6.0277, -6.3973, -5.1524, -5.7125, -6.5199, -5.0199, -5.2689, -5.9316, -5.1495, -4.9072, -5.8808, -5.9128, -5.8594, -5.952, -5.6001, -5.6197, -5.4027, -5.0826, -5.6443, -5.515, -5.901, -6.0225, -5.5683, -5.3656, -5.5829, -5.4529, -5.5844, -5.8337, -5.7337, -5.8139, -5.8745, -8.6688, -8.8904, -8.9255, -9.0251, -8.7555, -9.3882, -9.384, -8.6297, -9.2915, -9.2613, -7.8051, -9.5203, -9.5128, -9.4534, -9.4309, -8.76, -9.6548, -9.5575, -9.7011, -9.5536, -9.5493, -9.663, -9.22, -8.8136, -9.7037, -9.7504, -9.4037, -8.0533, -9.4758, -9.5125, -8.7152, -9.1881, -6.3669, -7.6191, -8.9578, -8.6168, -4.8955, -7.1661, -6.2611, -4.385, -8.1269, -6.4064, -5.6815, -6.5974, -7.1291, -5.2701, -6.3863, -4.322, -5.1123, -4.986, -5.8406, -5.3379, -6.2524, -7.0346, -5.7666, -5.3053, -6.0061, -6.4347, -4.7422, -3.8457, -5.8997, -5.8917, -4.3249, -6.0297, -6.0594, -4.9433, -6.3732, -4.7418, -5.902, -4.4893, -5.8657, -4.9666, -4.6583, -5.4143, -5.5554, -4.8015, -5.2448, -4.9808, -5.4127, -5.1498, -5.1571, -4.902, -4.9181, -4.7079, -4.6093, -5.4369, -5.3973, -5.4651, -8.295, -8.3872, -8.0014, -8.3532, -8.5418, -8.5025, -8.5584, -8.709, -8.703, -8.7784, -8.8029, -8.5915, -8.7368, -8.8438, -8.7563, -7.3828, -8.9497, -8.9947, -9.0072, -8.5745, -9.0211, -9.0486, -9.1458, -9.1263, -8.8346, -9.1127, -9.1861, -9.0595, -9.1506, -9.0167, -8.7063, -8.8412, -8.1557, -8.251, -8.6032, -7.985, -8.5175, -8.1346, -7.7694, -8.4787, -7.9012, -8.6646, -7.5683, -5.749, -5.6517, -6.7982, -5.6409, -6.8104, -5.2697, -8.0364, -6.7699, -7.2791, -7.2128, -4.3858, -6.6906, -7.5352, -7.0438, -5.8839, -6.2018, -6.5974, -6.0851, -4.6736, -4.3742, -5.4946, -6.6093, -7.429, -6.2868, -6.3285, -5.7483, -5.5235, -5.4639, -5.4928, -5.7669, -6.3449, -5.32, -5.4148, -5.6269, -5.9135, -5.4001, -5.3613, -6.1604, -5.1464, -5.655, -6.0469, -5.8225, -6.1138, -5.8244, -5.7401, -5.6228, -5.3478, -5.8869, -5.8638, -5.8848, -7.7868, -7.9366, -8.0411, -8.0394, -8.1701, -8.0092, -8.2823, -8.3182, -7.6943, -8.377, -8.1974, -8.4531, -7.5771, -8.4789, -8.3201, -8.4442, -8.5428, -8.622, -8.6476, -8.674, -8.3423, -8.5597, -8.7485, -8.725, -8.6325, -8.421, -8.1971, -8.7585, -8.8206, -7.854, -7.9826, -8.1834, -8.2822, -7.7049, -7.8115, -8.2155, -7.8119, -7.0906, -8.2226, -7.856, -8.1796, -8.2137, -7.834, -7.1041, -7.7346, -3.8542, -6.5791, -6.8868, -7.3747, -7.5062, -7.4167, -7.2705, -6.7409, -5.1623, -5.8109, -5.0254, -6.9128, -7.1996, -5.6172, -5.626, -4.7921, -5.7275, -6.8311, -5.2434, -6.1287, -5.6239, -5.1406, -5.6309, -6.4492, -5.7758, -5.5223, -6.2574, -6.8222, -5.9766, -5.68, -6.1252, -6.3632, -6.0574, -5.7169, -6.2028, -6.0957, -5.9005, -5.9852, -6.0417, -6.4259, -6.2218, -6.0918, -6.1761, -6.1829, -7.699, -7.5589, -7.8494, -8.1194, -8.1086, -8.1985, -8.1146, -8.2134, -7.9731, -8.1456, -8.373, -7.6868, -7.4137, -8.4674, -8.0091, -8.0385, -8.3399, -8.5922, -8.6304, -8.622, -8.4395, -7.3311, -8.5723, -8.4229, -8.785, -8.2565, -8.7953, -8.6921, -8.7906, -8.3221, -7.9701, -7.8474, -7.7331, -8.3221, -7.7315, -7.0727, -8.0314, -7.4915, -8.0015, -8.1237, -7.784, -7.4033, -7.6096, -5.2662, -7.3835, -6.5005, -8.0027, -7.5334, -5.0677, -4.7337, -5.1547, -5.9091, -6.1692, -4.5604, -5.9, -5.2058, -5.7585, -5.5524, -5.0766, -5.3937, -5.4907, -5.4209, -5.5098, -5.4911, -6.0434, -5.1688, -5.6703, -5.4317, -5.5735, -5.8312, -6.0627, -5.8668, -5.8615, -6.0911, -5.8594, -6.0872, -5.7444, -5.8135, -5.8045, -5.817, -6.0002, -5.9798, -5.9586], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.0705, 1.0526, 1.0512, 1.0409, 1.0385, 1.0384, 1.0374, 1.0372, 1.0347, 1.0344, 1.0342, 1.034, 1.0338, 1.0332, 1.0328, 1.032, 1.0316, 1.0315, 1.0306, 1.0299, 1.0295, 1.0286, 1.0265, 1.0259, 1.024, 1.024, 1.0234, 1.0219, 1.0201, 1.0199, 1.0188, 1.0159, 0.996, 0.9948, 0.9972, 0.9745, 0.9739, 0.8956, 0.9773, 0.8818, 1.0012, 1.003, 0.8763, 0.9127, 0.9292, 0.8397, 0.9184, 0.9561, 0.9296, 0.9717, 0.9637, 0.8287, 0.8711, 0.9173, 0.8823, 0.8786, 0.7519, 0.787, 0.814, 0.9011, 0.8501, 0.8833, 0.7999, 0.8571, 0.8532, 0.471, 0.6081, 0.773, 0.7997, 0.7191, 0.7105, 0.7661, 0.5382, 0.6179, 0.7657, 0.4253, 0.4616, 0.6151, 0.3936, 0.2324, 0.5365, 0.544, 0.5087, 0.5346, 0.3764, 0.3721, 0.2516, 0.0489, 0.363, 0.2888, 0.4667, 0.5287, -0.2877, -0.737, -0.3043, -0.7483, -0.4635, 0.1228, -0.5452, -0.3982, 0.255, 1.2008, 1.1903, 1.1885, 1.1869, 1.1819, 1.1746, 1.1735, 1.173, 1.1725, 1.1701, 1.166, 1.1653, 1.1627, 1.1605, 1.1605, 1.1602, 1.1589, 1.1568, 1.1541, 1.1538, 1.1537, 1.1532, 1.1531, 1.152, 1.152, 1.1518, 1.1513, 1.1507, 1.1496, 1.148, 1.1458, 1.1478, 1.1153, 1.1299, 1.1422, 1.1342, 1.0478, 1.1028, 1.0638, 1.0051, 1.12, 1.064, 1.0276, 1.0654, 1.0802, 0.9986, 1.0382, 0.9513, 0.9811, 0.9687, 1.0061, 0.9662, 1.0044, 1.0497, 0.9635, 0.9218, 0.9727, 0.9976, 0.8702, 0.7829, 0.953, 0.9495, 0.8102, 0.9594, 0.9564, 0.8394, 0.9825, 0.7587, 0.9157, 0.6991, 0.8961, 0.6939, 0.6203, 0.7609, 0.7973, 0.4791, 0.6069, 0.4349, 0.6239, 0.4643, 0.4259, 0.2188, 0.2215, -0.0033, -0.1896, 0.543, 0.4889, 0.4292, 1.651, 1.648, 1.647, 1.6448, 1.6428, 1.6426, 1.6404, 1.6356, 1.6346, 1.6336, 1.6329, 1.6329, 1.6322, 1.6301, 1.6259, 1.6248, 1.6216, 1.6199, 1.6193, 1.6171, 1.6152, 1.6134, 1.6133, 1.6133, 1.6126, 1.6119, 1.6101, 1.6098, 1.6096, 1.6095, 1.6082, 1.607, 1.5961, 1.5947, 1.5967, 1.5712, 1.5874, 1.5659, 1.5456, 1.5823, 1.5293, 1.5927, 1.4762, 1.2569, 1.218, 1.3423, 1.1446, 1.3122, 0.99, 1.4949, 1.2399, 1.3433, 1.3264, 0.7456, 1.2168, 1.3855, 1.259, 0.9172, 0.9949, 1.1009, 0.9162, 0.4472, 0.3304, 0.6349, 1.0208, 1.3135, 0.8659, 0.8706, 0.6316, 0.4481, 0.3511, 0.311, 0.4348, 0.7343, 0.1253, 0.1283, 0.2594, 0.4493, 0.0155, -0.0807, 0.5941, -0.5178, -0.0007, 0.447, 0.154, 0.4525, 0.0272, -0.126, -0.3442, -0.9281, 0.1049, -0.2513, -0.6115, 2.2484, 2.2453, 2.2422, 2.2413, 2.2345, 2.2322, 2.2289, 2.2239, 2.2181, 2.2166, 2.2163, 2.2134, 2.2126, 2.2119, 2.2085, 2.2081, 2.2068, 2.2047, 2.2014, 2.2011, 2.2003, 2.1997, 2.1986, 2.1982, 2.196, 2.196, 2.1956, 2.1946, 2.1927, 2.1913, 2.1878, 2.1871, 2.1845, 2.1664, 2.1641, 2.1809, 2.1378, 2.0656, 2.1656, 2.1195, 2.1576, 2.1529, 2.0484, 1.8296, 2.0099, 0.8504, 1.6226, 1.7175, 1.8719, 1.9022, 1.8665, 1.723, 1.4555, 0.6527, 0.9679, 0.5576, 1.4913, 1.6547, 0.3393, 0.3455, -0.3724, 0.3086, 1.2358, -0.1225, 0.5915, 0.0303, -0.5119, -0.0878, 0.7097, -0.0453, -0.3872, 0.4552, 1.1116, -0.0001, -0.4916, 0.1345, 0.4222, -0.0501, -0.5854, 0.1498, -0.0591, -0.4849, -0.7046, -0.6516, 0.4047, -0.3355, -0.9521, -0.6756, -0.7376, 2.5114, 2.5094, 2.498, 2.4872, 2.4865, 2.4861, 2.4829, 2.4818, 2.481, 2.4781, 2.4753, 2.4748, 2.4712, 2.4685, 2.4617, 2.4614, 2.4604, 2.4556, 2.4519, 2.4497, 2.4458, 2.4453, 2.4449, 2.4414, 2.4374, 2.4372, 2.4367, 2.4352, 2.4346, 2.4337, 2.4332, 2.4203, 2.4162, 2.4252, 2.3981, 2.3218, 2.3761, 2.2904, 2.3562, 2.3754, 2.2697, 2.1508, 2.1692, 1.2204, 2.0753, 1.5844, 2.3122, 2.0578, 0.6229, 0.4059, 0.5723, 0.947, 1.0853, -0.1407, 0.7977, 0.2395, 0.6539, 0.4836, 0.0585, 0.2203, 0.1699, 0.0796, 0.1445, 0.052, 0.6113, -0.4642, 0.0603, -0.2432, -0.1578, 0.1453, 0.4232, 0.1553, 0.1183, 0.4475, -0.0077, 0.3098, -0.4638, -0.5349, -0.6836, -1.1884, 0.0364, -0.3969, -0.8271]}, \"token.table\": {\"Topic\": [4, 4, 1, 2, 4, 3, 5, 4, 1, 2, 3, 4, 5, 2, 3, 4, 5, 2, 2, 3, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 4, 5, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 3, 5, 2, 5, 4, 1, 2, 3, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 2, 2, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 1, 3, 1, 2, 3, 4, 5, 1, 2, 1, 3, 4, 3, 3, 4, 1, 4, 5, 1, 2, 3, 4, 5, 3, 4, 1, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 3, 3, 2, 5, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 5, 5, 3, 1, 2, 3, 4, 5, 2, 2, 4, 1, 2, 3, 4, 5, 3, 5, 1, 2, 3, 4, 5, 2, 3, 1, 2, 3, 4, 5, 3, 4, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 2, 3, 1, 2, 3, 4, 5, 1, 5, 1, 3, 5, 1, 2, 3, 4, 5, 2, 4, 2, 3, 4, 1, 4, 1, 1, 3, 5, 1, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 4, 3, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 3, 5, 1, 3, 4, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 4, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 4, 5, 1, 2, 3, 4, 5, 1, 4, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 3, 4, 2, 3, 1, 2, 3, 4, 5, 1, 3, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 4, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 1, 2, 3, 4, 5, 1, 3, 4, 1, 1, 2, 3, 4, 5, 4, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 4, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 2, 3, 2, 4, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 2, 3, 1, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 2, 5, 2, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 5, 1, 2, 3, 1, 4, 5, 4, 1, 5, 2, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 4, 1, 2, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 5, 3, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 4, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 5, 1, 4, 1, 2, 3, 4, 5, 1, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 2, 3, 3, 1, 3, 5, 3, 3, 1, 4, 1, 5, 1, 5, 1, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 2, 1, 3, 1, 2, 3, 4, 5, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 4, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 3, 1, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 3, 4, 3, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 2, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 4, 3, 1, 2, 4, 5], \"Freq\": [0.9420087569218742, 0.8992308754305505, 0.9686987564209995, 0.04108857180133126, 0.9039485796292878, 0.967270381186773, 0.8485399277045941, 0.9421106561554372, 0.011239463371521681, 0.9103965330932562, 0.022478926743043363, 0.044957853486086725, 0.011239463371521681, 0.9403314526421124, 0.028069595601257085, 0.014034797800628543, 0.014034797800628543, 0.9560063258818591, 0.9348614172324212, 0.03223660059422142, 0.9422000842223881, 0.044433486903763836, 0.06665023035564575, 0.8664529946233948, 0.022216743451881918, 0.8261560530623135, 0.030437328270716817, 0.052178277035514545, 0.039133707776635905, 0.052178277035514545, 0.12354406004188555, 0.20807420638633356, 0.13004637899145846, 0.513683197016261, 0.01950695684871877, 0.03417012300064876, 0.9225933210175167, 0.03417012300064876, 0.3022437308908472, 0.11185397914858125, 0.5045328421170048, 0.061876669316236435, 0.019038975174226595, 0.9448382084709861, 0.9416183072799968, 0.6261926666994101, 0.1527165681898037, 0.04378969697198672, 0.03941072727478805, 0.13793754546175818, 0.08131245992258512, 0.5468076433326137, 0.19544829816254405, 0.09623217733957322, 0.08056647405173571, 0.0693119069639405, 0.8351405260655185, 0.05028510897383919, 0.022424440488333693, 0.022424440488333693, 0.9165653954642439, 0.11230754509835918, 0.8423065882376938, 0.064735655311788, 0.906299174365032, 0.9111964552206824, 0.0989728450298502, 0.019794569005970042, 0.8709610362626817, 0.058208400841204606, 0.34925040504722765, 0.13581960196281076, 0.4397968063557681, 0.019402800280401537, 0.8653904263125354, 0.01688809531918743, 0.08444047659593715, 0.08444047659593715, 0.8106285753209966, 0.9221522542374926, 0.9600538260778343, 0.04072703458066007, 0.7314575410686548, 0.12381018512520661, 0.06679233671228252, 0.037468871814207265, 0.9259279909595806, 0.027817609167871304, 0.8832090910799139, 0.04868081604377478, 0.03477201145983913, 0.013908804583935652, 0.9367546306384259, 0.332579925832921, 0.4503416894546946, 0.11970289159356107, 0.061469052439936764, 0.036881431463962056, 0.9793377877285753, 0.9615032345601897, 0.9655194857377954, 0.582993868522163, 0.18123030369790086, 0.1091748817457234, 0.06222968259506234, 0.06550492904743405, 0.03688462063122312, 0.9590001364118012, 0.030634427074588137, 0.9190328122376441, 0.030634427074588137, 0.9237880873993917, 0.06262229607568465, 0.8767121450595851, 0.17455504164866398, 0.8029531915838543, 0.03491100832973279, 0.03538303617178527, 0.8011730333182809, 0.06318399316390227, 0.07329343207012665, 0.030328316718673094, 0.9761541953058858, 0.9326855215221584, 0.9278953273577013, 0.07599931836155185, 0.8184541977397892, 0.03215355776834886, 0.0569994887711639, 0.01607677888417443, 0.9049556626465546, 0.0762197945961155, 0.7951324251076246, 0.0639869880559982, 0.047049255923528085, 0.016937732132470112, 0.9377242401008412, 0.9596313325730722, 0.06755740747866208, 0.9458037047012692, 0.9691979390098738, 0.9031445675874371, 0.009506784921973023, 0.019013569843946046, 0.019013569843946046, 0.03802713968789209, 0.10715600453702191, 0.042862401814808763, 0.06429360272221316, 0.7929544335739622, 0.9461479215050264, 0.9576507693669597, 0.9124097364967197, 0.057025608531044984, 0.12935965675084138, 0.840837768880469, 0.2239214427045548, 0.3512031048734596, 0.29109787551592126, 0.062462297175481074, 0.07189056844725181, 0.9197449036983641, 0.09075933423648154, 0.7584142067807135, 0.10119144161998517, 0.02677574228432597, 0.022950636243707974, 0.1284872013436972, 0.6783198197063655, 0.09954864248250415, 0.05556203301349069, 0.03762012651955099, 0.04863790722414246, 0.8016868845910378, 0.0788269530874033, 0.028511876648635234, 0.04192923036564005, 0.9032968541738442, 0.017711703023016553, 0.02656755453452483, 0.017711703023016553, 0.035423406046033105, 0.22330818076127462, 0.01116540903806373, 0.6922553603599513, 0.055827045190318655, 0.02233081807612746, 0.9670167337782696, 0.868801375118548, 0.9271866972698395, 0.9511887756417796, 0.45512158483031107, 0.19918957673742185, 0.25415880711303085, 0.029553349664305912, 0.062062034295042416, 0.9239784684191006, 0.9105268079076628, 0.03793861699615262, 0.2576631769395517, 0.1980189230183592, 0.4461390193305201, 0.08350195548966953, 0.016700391097933906, 0.9111321607235072, 0.04795432424860565, 0.14385626053204445, 0.5376007667296661, 0.19160165734655918, 0.049605607080015324, 0.07688869097402375, 0.9235026214980857, 0.972454228953299, 0.8257675203562604, 0.04346144843980318, 0.07062485371468018, 0.038028767384827786, 0.027163405274876987, 0.964459761101658, 0.8975221431181946, 0.09901985917113654, 0.07921588733690922, 0.7129429860321831, 0.09901985917113654, 0.009901985917113653, 0.9580307737630457, 0.1437352412466311, 0.5345942306015051, 0.06808511427472, 0.022695038091573333, 0.22947205181479702, 0.05079201208830999, 0.9142562175895798, 0.781534053460912, 0.05431510796253442, 0.0709113909510866, 0.043753836969819396, 0.04978884896565655, 0.09319622537023697, 0.9319622537023697, 0.03365158666629652, 0.9085928399900062, 0.03365158666629652, 0.2128100266058401, 0.4483703455882511, 0.10806388878871169, 0.17773665919196, 0.052136086696308266, 0.9650648724680116, 0.9178628816203536, 0.07468099203227972, 0.03734049601613986, 0.8588314083712169, 0.9520381643158521, 0.9166285365227976, 0.9660615192960363, 0.9701789616320812, 0.026221053017083273, 0.026221053017083273, 0.03499647235911076, 0.03499647235911076, 0.9099082813368798, 0.030612621745035068, 0.9183786523510521, 0.030612621745035068, 0.030612621745035068, 0.9201486683778963, 0.007932316106706003, 0.015864632213412007, 0.007932316106706003, 0.047593896640236014, 0.8957224847050025, 0.115989588979957, 0.6586876136590247, 0.07359130580190483, 0.06904863260425638, 0.0823738073173585, 0.028165400689760825, 0.8480915096583538, 0.06571926827610859, 0.04694233448293471, 0.006258977931057961, 0.30340888274394273, 0.23377405719615257, 0.11440007054279808, 0.30838279885449915, 0.039791328884451506, 0.939156133559181, 0.037566245342367244, 0.9333582365442238, 0.11092742183481351, 0.7179469246530985, 0.055463710917406754, 0.0770329318297316, 0.0385164659148658, 0.4374360499488653, 0.19063935960609332, 0.11822595944563927, 0.18472806163381136, 0.06945775117431308, 0.18601963517298098, 0.47350452589486064, 0.1757260585230927, 0.07426080297419398, 0.09117167889901043, 0.38849874270923435, 0.1284798991636838, 0.3380244966092157, 0.04435615566365274, 0.10247801480912874, 0.056873246457728774, 0.9099719433236604, 0.953320816427404, 0.9608479203041236, 0.02745279772297496, 0.02745279772297496, 0.8024321455318262, 0.03566365091252561, 0.06686934546098551, 0.04012160727659131, 0.05795343273285412, 0.0737224230747856, 0.024574141024928532, 0.8355207948475701, 0.049148282049857064, 0.024574141024928532, 0.08247694932617144, 0.7718467841107544, 0.08591348888142858, 0.024055776886800002, 0.03574001137467429, 0.5443413841404126, 0.1495899986950752, 0.1745216651442544, 0.06336798555833047, 0.06856208273524281, 0.1577402641189249, 0.35018338634401325, 0.35018338634401325, 0.10410857431849044, 0.037857663388541976, 0.4950627215272916, 0.19759708049432242, 0.20687058968719677, 0.04850758654734269, 0.05207432085229436, 0.8568754646316993, 0.02040179677694522, 0.06120539033083566, 0.04590404274812675, 0.015301347582708916, 0.12165248436237701, 0.060826242181188504, 0.030413121090594252, 0.7603280272648563, 0.030413121090594252, 0.08610836969706316, 0.10045976464657368, 0.2296223191921684, 0.5740557979804211, 0.014351394949510526, 0.8353990332333123, 0.017273288281139918, 0.05496046271271792, 0.017273288281139918, 0.075374348863156, 0.9312268774743532, 0.04656134387371766, 0.04386782123968574, 0.770123972874483, 0.10235824955926673, 0.04191814029569971, 0.04191814029569971, 0.041708506847892526, 0.7626698395043204, 0.09930596868545839, 0.0675280587061117, 0.029791790605637518, 0.8041448589214428, 0.030592467458967935, 0.06118493491793587, 0.01311105748241483, 0.09614775487104207, 0.17439258207316935, 0.14048291333671975, 0.6297509908197781, 0.03390966873644959, 0.02422119195460685, 0.031399794333259144, 0.031399794333259144, 0.031399794333259144, 0.9105940356645151, 0.9663702987413874, 0.8621231994427869, 0.012964258638237398, 0.019446387957356096, 0.025928517276474796, 0.08426768114854308, 0.29228761648131474, 0.21637651772236388, 0.2647922578757105, 0.19545613617462151, 0.031679434915152724, 0.8565691790986526, 0.05820477221185731, 0.9021739692837883, 0.029102386105928656, 0.07664175630066214, 0.03832087815033107, 0.8813801974576145, 0.055227053358619695, 0.7672082547656898, 0.0820942685060563, 0.043286068848647864, 0.05224180723112674, 0.9708230666525391, 0.018348552896955417, 0.08562658018579195, 0.7155935629812613, 0.1712531603715839, 0.00611618429898514, 0.16316141574350257, 0.6409652036814105, 0.11096436327969748, 0.06113990410970174, 0.023725932938093212, 0.11739750510748001, 0.6272625820341268, 0.15767256160420673, 0.07112403594102804, 0.026564398965926134, 0.11330803101749932, 0.8498102326312449, 0.9790514232323714, 0.6936720668692389, 0.1128533731349087, 0.06470260059734766, 0.05116019582115861, 0.07824500537353671, 0.12048672030057953, 0.7952123539838248, 0.045182520112717325, 0.01506084003757244, 0.024097344060115905, 0.32493800911175696, 0.09395797853833936, 0.465874976919266, 0.06851102601753911, 0.04697898926916968, 0.03627117903173271, 0.7840154852243763, 0.0641720859792194, 0.10602344640044946, 0.01116036277899468, 0.03880809597614899, 0.7592888343159585, 0.09786389420072354, 0.05905579822457455, 0.042182713017553254, 0.04869947217771848, 0.8495352368779779, 0.06222710333819584, 0.029760788553050185, 0.013527631160477355, 0.038317126385642934, 0.8429767804841445, 0.07663425277128587, 0.49848855906696843, 0.21501330552030182, 0.13264502430108172, 0.04813730720603772, 0.10590207585328298, 0.055015626491658164, 0.8802500238665306, 0.4042141555978257, 0.20675915887356813, 0.2915304140117311, 0.060993951867702595, 0.03514905700850658, 0.9540338986189867, 0.07491449826240364, 0.7365088021942334, 0.09567393753993718, 0.03610337265658007, 0.056862811934113605, 0.031819110958173795, 0.031819110958173795, 0.9227542177870401, 0.9340718314797699, 0.054945401851751174, 0.5871151297699914, 0.1124263014453175, 0.12718935113005617, 0.08403582128235854, 0.08971391731495033, 0.053778999636709214, 0.9142429938240567, 0.917153778476241, 0.2146732713274833, 0.3645564176507053, 0.29140627651686185, 0.09016874539763554, 0.039411504610887056, 0.8959534432470284, 0.02674487890289637, 0.04011731835434455, 0.02674487890289637, 0.342808976915027, 0.022853931794335133, 0.022853931794335133, 0.6170561584470486, 0.017715566050495103, 0.9212094346257454, 0.017715566050495103, 0.017715566050495103, 0.017715566050495103, 0.8881872431906862, 0.038362284192792584, 0.7572381314577318, 0.11008307637931784, 0.06338116518809209, 0.03169058259404604, 0.3391830311596998, 0.10083819845288372, 0.28647215469569237, 0.2062599513808985, 0.06416976265183509, 0.9140143833527914, 0.9362816113431113, 0.7234122250236942, 0.09346411176016721, 0.06635951934971872, 0.030843156880855177, 0.08598698281935382, 0.8210407844207713, 0.0345701382914009, 0.07778281115565203, 0.02160633643212556, 0.04321267286425112, 0.9516939760136857, 0.9230212920977025, 0.16146592197993917, 0.29201702719054856, 0.25933002347265843, 0.238457599411837, 0.04883359591588404, 0.17257361612629485, 0.17257361612629485, 0.6519447720326694, 0.9009984357793197, 0.04421737150979683, 0.7816999606196225, 0.05685090622688164, 0.05764050214669944, 0.05921969398633504, 0.04782302125926185, 0.8279360555509707, 0.056789837745373446, 0.035867265944446385, 0.03287832711574252, 0.33031290391894114, 0.23710948859192615, 0.16776614758862698, 0.1386866820065983, 0.1260110175221243, 0.05035452106367251, 0.09351553911824895, 0.6546087738277426, 0.19422458124559397, 0.007193503009096073, 0.9453481232497392, 0.9670878196014768, 0.43017498010899413, 0.36567915565135145, 0.048067642756167664, 0.03924510073130145, 0.11682262543271128, 0.9615333936473598, 0.9445856015490809, 0.9358142523586734, 0.9663752581801408, 0.05545682499974565, 0.20334169166573407, 0.0739424333329942, 0.6654818999969478, 0.01848560833324855, 0.9498521567605773, 0.08290609212990037, 0.9119670134289041, 0.4304779136321215, 0.17302166946628678, 0.15641158919752324, 0.09689213490112059, 0.14395402899595058, 0.2676092497698893, 0.19069162109351395, 0.46631312385052576, 0.025639209558791794, 0.0496759685201591, 0.5410898490033286, 0.13019116163836436, 0.1483190449044657, 0.09723137388181641, 0.08239946939136984, 0.12756710479064892, 0.118455168734174, 0.7016190763485691, 0.03644774422589969, 0.009111936056474923, 0.04785154543645374, 0.7751950360705505, 0.07656247269832597, 0.02871092726187224, 0.07273434906340968, 0.9438393344506597, 0.9733162460425224, 0.522018014956431, 0.11935380247025992, 0.21103734623634193, 0.048732694434223775, 0.09870435567609731, 0.5055299460109314, 0.10748204257529712, 0.21177605846403882, 0.09336363867769454, 0.08197782908285374, 0.8616769137229284, 0.009118274219290248, 0.04103223398680612, 0.004559137109645124, 0.08206446797361223, 0.0436120923059065, 0.9158539384240365, 0.0436120923059065, 0.4404251785257911, 0.1309814657325773, 0.35119405499547285, 0.04338761052391622, 0.034382634754801536, 0.9176024041443991, 0.7593538132316728, 0.0369722830412425, 0.09669674026171116, 0.0455043483584523, 0.06256847899287192, 0.9242204894360689, 0.0901089205832198, 0.0901089205832198, 0.6908350578046851, 0.0901089205832198, 0.036043568233287915, 0.3125312904167534, 0.19888354844702488, 0.0909181935757828, 0.35230800010615837, 0.0454590967878914, 0.059385087258012705, 0.9501613961282033, 0.9745650769413939, 0.6324705166980208, 0.17913326343187616, 0.09206849293705366, 0.03802829056095695, 0.058043180329881656, 0.15598123740983783, 0.4775721836745652, 0.24135368422262973, 0.07253448488605628, 0.05199374580327928, 0.8536289178458677, 0.013880145005623864, 0.0416404350168716, 0.03470036251405966, 0.06246065252530739, 0.94227564727079, 0.9952832402377194, 0.9718393292147824, 0.03157109783259359, 0.03157109783259359, 0.06314219566518718, 0.12628439133037436, 0.7577063479822461, 0.28549115355122784, 0.26568829896963975, 0.26073758532424274, 0.15347212300730745, 0.0346549955177791, 0.2692613058008425, 0.5039838577162367, 0.08599444844948373, 0.052865439620584265, 0.08740419350603265, 0.4660619326011709, 0.1292805827028889, 0.21836468170824092, 0.03693730934368254, 0.14992202027729973, 0.814753446104577, 0.014293920107097843, 0.05717568042839137, 0.06074916045516583, 0.05360220040161691, 0.5843002121388587, 0.22485265616183725, 0.023752041143856047, 0.022696394870795777, 0.14515136254578695, 0.07542293723021999, 0.20112783261391998, 0.050281958153479994, 0.025140979076739997, 0.6788064350719799, 0.7002956158848384, 0.07591700260698468, 0.10225555453185692, 0.032535858260136295, 0.08986094186132881, 0.0235797019911415, 0.3694153311945502, 0.5619828974555391, 0.019649751659284585, 0.0235797019911415, 0.05506659103835775, 0.3707817129916089, 0.5176259557605629, 0.022026636415343102, 0.03303995462301465, 0.9278887601030461, 0.237004422804907, 0.4909377329530216, 0.03216488595209452, 0.04062932962369834, 0.19976087064985018, 0.08347143449294439, 0.9181857794223882, 0.0583686485556032, 0.875529728334048, 0.943138117493548, 0.3581897091533131, 0.15842426057749737, 0.39259040573585535, 0.05673097331156096, 0.03409893608620419, 0.25571001456163617, 0.4732386707846171, 0.17199125636953885, 0.05044142752996659, 0.0490402767652453, 0.9112995156283044, 0.043395215029919255, 0.043395215029919255, 0.9682401006210312, 0.9201724541665227, 0.2870048038855527, 0.07827403742333257, 0.6001009535788829, 0.16531584420963946, 0.029173384272289316, 0.2042136899060252, 0.5640187625975934, 0.029173384272289316, 0.25506856157908503, 0.17763703395686278, 0.4418151870209151, 0.07743152762222223, 0.04782535529607844, 0.9135176705426805, 0.025191742555179784, 0.9069027319864722, 0.05038348511035957, 0.025191742555179784, 0.16012466734025352, 0.04003116683506338, 0.7472484475878497, 0.026687444556708916, 0.013343722278354458, 0.04293150951985787, 0.22539042497925385, 0.6439726427978681, 0.06976370296976904, 0.021465754759928936, 0.9761867843086781, 0.220950389200125, 0.2679611103065346, 0.2193833651632447, 0.2679611103065346, 0.023505360553204787, 0.04994985930924643, 0.2622367613735438, 0.12487464827311609, 0.5369609875743991, 0.024974929654623217, 0.0524100849170841, 0.8647664011318876, 0.019653781843906537, 0.02620504245854205, 0.039307563687813074, 0.05901948289040389, 0.05901948289040389, 0.05901948289040389, 0.8262727604656545, 0.16140868542208944, 0.8070434271104472, 0.9625206319491653, 0.034829035626823324, 0.8928898224331071, 0.018997655796449086, 0.034829035626823324, 0.015831379830374238, 0.9523396933642757, 0.2771608125085208, 0.3079564583428009, 0.28771931965170255, 0.03959440178693154, 0.08710768393124939, 0.850220564079083, 0.013284696313735671, 0.042511028203954145, 0.034540210415712744, 0.06110960304318409, 0.9206906741064119, 0.02360745318221569, 0.02360745318221569, 0.9493147555966078, 0.025657155556665076, 0.025657155556665076, 0.9360474416829777, 0.9047134159120858, 0.8741093054587178, 0.9382780483710909, 0.09118119883578513, 0.8662213889399587, 0.9651437175512478, 0.5826547223117677, 0.08540922636296996, 0.03275970326250903, 0.03626967146920643, 0.2632476155023047, 0.9207286561562992, 0.4387524956974377, 0.18018373953235842, 0.18629166290633667, 0.10485268458662664, 0.09009186976617921, 0.9460401251981603, 0.9559344487582425, 0.03676670956762471, 0.9759894275641926, 0.5681676436872829, 0.2082870537595462, 0.0862727441607588, 0.014789613284701507, 0.12201430959878742, 0.19770212298653117, 0.5864480073046068, 0.07682724986523232, 0.04660853158490761, 0.09219269983827878, 0.10866673150379308, 0.06520003890227585, 0.1304000778045517, 0.6737337353235171, 0.021733346300758617, 0.9485206714491995, 0.9174120750638536, 0.9485658326129767, 0.7706415879497214, 0.03484283775304591, 0.08608230503693695, 0.049189888592535404, 0.05943778204931361, 0.9402156764900937, 0.8420777869755555, 0.005847762409552469, 0.04678209927641975, 0.029238812047762346, 0.0760209113241821, 0.014555463503410459, 0.029110927006820917, 0.9461051277216798, 0.014555463503410459, 0.9790981965486618, 0.027197172126351716, 0.04615298589925, 0.9230597179850001, 0.7343526048958715, 0.06445728193443385, 0.05524909880094331, 0.046040915667452754, 0.10129001446839607, 0.5322492796644629, 0.02314127302888969, 0.034711909543334536, 0.034711909543334536, 0.3818310049766799, 0.937784524308371, 0.19773108456690935, 0.5893600178125166, 0.08944217072493477, 0.062290083183436706, 0.061012337887366215, 0.9234762679717278, 0.02495881805328994, 0.02495881805328994, 0.02495881805328994, 0.7385274121646933, 0.05527899791651896, 0.06854595741648352, 0.03980087849989365, 0.09729103633307337, 0.036983044763003854, 0.9060845966935944, 0.018491522381501927, 0.018491522381501927, 0.8895699748308415, 0.7968723902253263, 0.028207872220365533, 0.028207872220365533, 0.02468188819281984, 0.11988345693655351, 0.8242823444460028, 0.02221470148152348, 0.012861142962987277, 0.023383896296340505, 0.11925787111133657, 0.11521616427060956, 0.6258332559244474, 0.12307181183451475, 0.05193455889470658, 0.08422999887965017, 0.9275291501548258, 0.49666810835612724, 0.09413511530370729, 0.2170727658869071, 0.101862624768937, 0.08992011014085473, 0.03946885681128564, 0.26598577416301195, 0.6297856717279057, 0.056629229337931575, 0.008580186263322966, 0.9545195766355958, 0.03408998487984271, 0.9689897770089687, 0.026916382694693576, 0.04221116039528062, 0.8004486711993954, 0.07074277806986845, 0.053154794571834856, 0.03322174660739678, 0.03452522373671585, 0.0690504474734317, 0.8976558171546122, 0.8196530944489807, 0.10362091676982853, 0.018628479419295015, 0.027942719128942525, 0.030271279056354402, 0.015103457596835203, 0.07551728798417602, 0.815586710229101, 0.07551728798417602, 0.015103457596835203, 0.06434039315235643, 0.2955928207144491, 0.5016685726951849, 0.11655868324702252, 0.021446797717452143, 0.9670096362718723, 0.11515694709734127, 0.10884697739337737, 0.5852496900426521, 0.1545942577471157, 0.036282325797792454, 0.057032415287563205, 0.1376644506941181, 0.6548894583020188, 0.13963108570403404, 0.00786654003966389, 0.045517047884758084, 0.8496515605154842, 0.04172396056102824, 0.022758523942379042, 0.0379308732372984, 0.7901744373750013, 0.04382696716272438, 0.033514739595024524, 0.07347462141986146, 0.060584336960236636, 0.9110837136120729, 0.012480598816603738, 0.024961197633207477, 0.049922395266414954, 0.036256636017610734, 0.9426725364578791, 0.9548392627814347, 0.011563352516231305, 0.8383430574267696, 0.09250682012985044, 0.05203508632304087, 0.011563352516231305, 0.7580415641172076, 0.012550357021808073, 0.08785249915265651, 0.017570499830531303, 0.12299349881371911, 0.9523908405165905, 0.96797759321168, 0.9228134744239895, 0.955118678473306, 0.9239460222207565, 0.05543676133324539, 0.8643758403248076, 0.922003382165777, 0.9356204871226834, 0.035974588616664825, 0.9353393040332855, 0.9714814384066467, 0.9358576626593786, 0.05877897610558152, 0.8816846415837227, 0.0628808750040595, 0.9432131250608926, 0.3078641863430155, 0.26225467725516133, 0.2926610166470641, 0.09248594898370424, 0.0443425782798582, 0.1054345393503662, 0.6994800689309018, 0.14497249160675352, 0.024894266235503133, 0.025382389102865936, 0.9353519952394626, 0.912166799161994, 0.9356387711108413, 0.033415670396815755, 0.02703866985768441, 0.12167401435957985, 0.16223201914610647, 0.6354087416555837, 0.05407733971536882, 0.2071840575043197, 0.7458626070155508, 0.7485428169334681, 0.03179139376937509, 0.020230886944147788, 0.026011140356761442, 0.1734076023784096, 0.971116298862946, 0.8862535663087268, 0.020142126507016515, 0.020142126507016515, 0.04028425301403303, 0.04028425301403303, 0.7335112566417066, 0.026011037469564062, 0.13265629109477672, 0.03381434871043328, 0.07283090491477938, 0.05815683014347477, 0.9305092822955964, 0.5674749317753657, 0.21514159501373753, 0.05404523159765387, 0.0966578180496502, 0.06651720812018938, 0.9704201241192494, 0.03867638072608069, 0.7638585193400936, 0.08315421856107348, 0.08508803759737751, 0.027073466508256483, 0.044697625058975864, 0.044697625058975864, 0.044697625058975864, 0.8492548761205414, 0.325879744976219, 0.09522460080473932, 0.38724670993927324, 0.09522460080473932, 0.09522460080473932, 0.9796860943182563, 0.06141328457004375, 0.9211992685506561, 0.24641885400437155, 0.46594676163921844, 0.16427923600291436, 0.026402020071896952, 0.09680740693028883, 0.23880475005770274, 0.11144221669359461, 0.1353226916993649, 0.4537290251096352, 0.055721108346797305, 0.39597382130568054, 0.31091277821038615, 0.09092732192945256, 0.15985609823081176, 0.042530521547647165, 0.29568340312627067, 0.22368484397259247, 0.29148931230178454, 0.1439971183073564, 0.04543598393193284, 0.9411714102257781, 0.9255956191129298, 0.9672198932550775, 0.5461711281308884, 0.2424300804637376, 0.07360277946883176, 0.0701966146241977, 0.06753092039796234, 0.4904585147351183, 0.21878651617430683, 0.11808676204109939, 0.0970774608190633, 0.07679261825985603, 0.9714315433287316, 0.6312017974581234, 0.12797989200430454, 0.1230097991109335, 0.07827896307059404, 0.039760743146968404, 0.9397676629802486, 0.04946145594632887, 0.024730727973164435, 0.2832791456891354, 0.6924601339067754, 0.22892969702910856, 0.4526473344060658, 0.1892378581396484, 0.062544715825816, 0.06655399248131702, 0.934329763739439, 0.38561606427305767, 0.33534825589460554, 0.0833206138875714, 0.14322882387285, 0.05302220883754543, 0.140186977104924, 0.6497717551943558, 0.07060511985576465, 0.11869846236621302, 0.020465252132105694, 0.9576009282208429, 0.1026405781218086, 0.8724449140353732, 0.25170204094639237, 0.5446552497145546, 0.132143571496856, 0.025869376430601436, 0.04544620183754307, 0.9443391227291289, 0.5790959755666715, 0.21716099083750182, 0.07737920363175352, 0.04368180850179634, 0.0823714103176731, 0.05789581483306813, 0.05789581483306813, 0.868437222496022, 0.9337296527445977, 0.8958906573608577, 0.012272474758367914, 0.024544949516735828, 0.049089899033471655], \"Term\": [\"abgefertigt\", \"abgeht\", \"abszess\", \"abwechslungsreiche\", \"abwechslungsreiche\", \"and\", \"angelegenheiten\", \"angeleitet\", \"angenehme\", \"angenehme\", \"angenehme\", \"angenehme\", \"angenehme\", \"angenehmen\", \"angenehmen\", \"angenehmen\", \"angenehmen\", \"angstpatientin\", \"anna\", \"anna\", \"ansehen\", \"anstrengend\", \"anstrengend\", \"anstrengend\", \"anstrengend\", \"antwort\", \"antwort\", \"antwort\", \"antwort\", \"antwort\", \"anwendungen\", \"anwendungen\", \"anwendungen\", \"anwendungen\", \"anwendungen\", \"apotheke\", \"apotheke\", \"apotheke\", \"arbeiten\", \"arbeiten\", \"arbeiten\", \"arbeiten\", \"arbeiten\", \"arme\", \"arthroskopie\", \"arzt\", \"arzt\", \"arzt\", \"arzt\", \"arzt\", \"aufenthalt\", \"aufenthalt\", \"aufenthalt\", \"aufenthalt\", \"aufenthalt\", \"aufgehoben\", \"aufgehoben\", \"aufgehoben\", \"aufgehoben\", \"aufgehoben\", \"aufrecht\", \"aufregung\", \"aufregung\", \"aufwand\", \"aufwand\", \"ausgesetzt\", \"ausgezeichnete\", \"ausgezeichnete\", \"ausgezeichnete\", \"auswahl\", \"auswahl\", \"auswahl\", \"auswahl\", \"auswahl\", \"autounfall\", \"balkon\", \"balkon\", \"balkon\", \"balkon\", \"bauer\", \"becker\", \"bedanken\", \"bedanken\", \"bedanken\", \"bedanken\", \"bedanken\", \"bed\\u00fcrfnissen\", \"beeindruckt\", \"beeindruckt\", \"beeindruckt\", \"beeindruckt\", \"beeindruckt\", \"beginnend\", \"behandlung\", \"behandlung\", \"behandlung\", \"behandlung\", \"behandlung\", \"behandlungszimmer\", \"behutsam\", \"beigebracht\", \"bekommen\", \"bekommen\", \"bekommen\", \"bekommen\", \"bekommen\", \"belange\", \"belange\", \"bereue\", \"bereue\", \"bereue\", \"besitzen\", \"besitzt\", \"besitzt\", \"bestellen\", \"bestellen\", \"bestellen\", \"bestens\", \"bestens\", \"bestens\", \"bestens\", \"bestens\", \"bester\", \"bestm\\u00f6glich\", \"betracht\", \"betreut\", \"betreut\", \"betreut\", \"betreut\", \"betreut\", \"betreuten\", \"betreuung\", \"betreuung\", \"betreuung\", \"betreuung\", \"betreuung\", \"betteln\", \"bet\\u00e4ubung\", \"bistro\", \"bistro\", \"blieben\", \"blutdruck\", \"blutdruck\", \"blutdruck\", \"blutdruck\", \"blutdruck\", \"bruch\", \"bruch\", \"bruch\", \"bruch\", \"cannabis\", \"christian\", \"christina\", \"christina\", \"clinic\", \"clinic\", \"daf\\u00fcr\", \"daf\\u00fcr\", \"daf\\u00fcr\", \"daf\\u00fcr\", \"daf\\u00fcr\", \"daniel\", \"dank\", \"dank\", \"dank\", \"dank\", \"dank\", \"danke\", \"danke\", \"danke\", \"danke\", \"danke\", \"dankesch\\u00f6n\", \"dankesch\\u00f6n\", \"dankesch\\u00f6n\", \"dankesch\\u00f6n\", \"dankesch\\u00f6n\", \"daraufhin\", \"daraufhin\", \"daraufhin\", \"daraufhin\", \"daraufhin\", \"depressionen\", \"depressionen\", \"depressionen\", \"depressionen\", \"depressionen\", \"derma\\u00dfen\", \"diskriminierung\", \"drinnen\", \"ehrliche\", \"einfach\", \"einfach\", \"einfach\", \"einfach\", \"einfach\", \"eingespielt\", \"eingespieltes\", \"eingespieltes\", \"einrichtung\", \"einrichtung\", \"einrichtung\", \"einrichtung\", \"einrichtung\", \"einzulassen\", \"einzulassen\", \"empfehlen\", \"empfehlen\", \"empfehlen\", \"empfehlen\", \"empfehlen\", \"endet\", \"engmaschig\", \"entt\\u00e4uscht\", \"entt\\u00e4uscht\", \"entt\\u00e4uscht\", \"entt\\u00e4uscht\", \"entt\\u00e4uscht\", \"erfahrene\", \"erfahrenen\", \"ergotherapie\", \"ergotherapie\", \"ergotherapie\", \"ergotherapie\", \"ergotherapie\", \"erkenntnisse\", \"erkl\\u00e4rt\", \"erkl\\u00e4rt\", \"erkl\\u00e4rt\", \"erkl\\u00e4rt\", \"erkl\\u00e4rt\", \"erm\\u00f6glichen\", \"erm\\u00f6glichen\", \"erst\", \"erst\", \"erst\", \"erst\", \"erst\", \"erstaufnahme\", \"erstaufnahme\", \"erzielen\", \"erzielen\", \"erzielen\", \"essen\", \"essen\", \"essen\", \"essen\", \"essen\", \"essens\", \"fahrl\\u00e4ssigkeit\", \"fahrrad\", \"fahrrad\", \"fahrrad\", \"fehldiagnosen\", \"feine\", \"feste\", \"flasche\", \"flasche\", \"flasche\", \"fraktur\", \"fraktur\", \"fraktur\", \"frauenklinik\", \"frauenklinik\", \"frauenklinik\", \"frauenklinik\", \"frechheit\", \"frechheit\", \"frechheit\", \"frechheit\", \"frechheit\", \"freunden\", \"freundlich\", \"freundlich\", \"freundlich\", \"freundlich\", \"freundlich\", \"freundliches\", \"freundliches\", \"freundliches\", \"freundliches\", \"freundliches\", \"fr\\u00fchst\\u00fcck\", \"fr\\u00fchst\\u00fcck\", \"fr\\u00fchst\\u00fcck\", \"fr\\u00fchst\\u00fcck\", \"fr\\u00fchst\\u00fcck\", \"fuhr\", \"fuhr\", \"f\\u00f6rmlich\", \"f\\u00fchlte\", \"f\\u00fchlte\", \"f\\u00fchlte\", \"f\\u00fchlte\", \"f\\u00fchlte\", \"gab\", \"gab\", \"gab\", \"gab\", \"gab\", \"ganz\", \"ganz\", \"ganz\", \"ganz\", \"ganz\", \"geben\", \"geben\", \"geben\", \"geben\", \"geben\", \"geborgenheit\", \"geborgenheit\", \"geburtenstation\", \"geburtsstation\", \"geburtsstation\", \"geburtsstation\", \"gefragt\", \"gefragt\", \"gefragt\", \"gefragt\", \"gefragt\", \"gef\\u00fchle\", \"gef\\u00fchle\", \"gef\\u00fchle\", \"gef\\u00fchle\", \"gef\\u00fchle\", \"gef\\u00fchlt\", \"gef\\u00fchlt\", \"gef\\u00fchlt\", \"gef\\u00fchlt\", \"gef\\u00fchlt\", \"gehen\", \"gehen\", \"gehen\", \"gehen\", \"gehen\", \"geholfen\", \"geholfen\", \"geholfen\", \"geholfen\", \"geholfen\", \"geht\", \"geht\", \"geht\", \"geht\", \"geht\", \"geld\", \"geld\", \"geld\", \"geld\", \"geld\", \"gelegenheit\", \"gelegenheit\", \"gelegenheit\", \"gelegenheit\", \"gelegenheit\", \"gel\\u00e4nde\", \"gel\\u00e4nde\", \"gel\\u00e4nde\", \"gel\\u00e4nde\", \"gel\\u00e4nde\", \"gesagt\", \"gesagt\", \"gesagt\", \"gesagt\", \"gesagt\", \"gesammelt\", \"gesammelt\", \"gesamte\", \"gesamte\", \"gesamte\", \"gesamte\", \"gesamte\", \"gesamten\", \"gesamten\", \"gesamten\", \"gesamten\", \"gesamten\", \"geschickt\", \"geschickt\", \"geschickt\", \"geschickt\", \"geschickt\", \"gespr\\u00e4che\", \"gespr\\u00e4che\", \"gespr\\u00e4che\", \"gespr\\u00e4che\", \"gespr\\u00e4che\", \"gest\\u00fcrzt\", \"gest\\u00fcrzt\", \"gest\\u00fcrzt\", \"gest\\u00fcrzt\", \"gesundheitlich\", \"gewartet\", \"gewartet\", \"gewartet\", \"gewartet\", \"gewartet\", \"gibt\", \"gibt\", \"gibt\", \"gibt\", \"gibt\", \"gips\", \"grenzen\", \"grenzen\", \"grenzen\", \"gro\\u00dfem\", \"gro\\u00dfem\", \"gro\\u00dfem\", \"gro\\u00dfes\", \"gro\\u00dfes\", \"gro\\u00dfes\", \"gro\\u00dfes\", \"gro\\u00dfes\", \"gro\\u00dfk\\u00fcche\", \"gruppe\", \"gruppe\", \"gruppe\", \"gruppe\", \"gruppe\", \"gut\", \"gut\", \"gut\", \"gut\", \"gut\", \"gute\", \"gute\", \"gute\", \"gute\", \"gute\", \"hallux\", \"hallux\", \"handchirurgie\", \"hause\", \"hause\", \"hause\", \"hause\", \"hause\", \"hebammen\", \"hebammen\", \"hebammen\", \"hebammen\", \"hebammen\", \"helfen\", \"helfen\", \"helfen\", \"helfen\", \"helfen\", \"hervorragend\", \"hervorragend\", \"hervorragend\", \"hervorragend\", \"hervorragend\", \"herzlich\", \"herzlich\", \"herzlich\", \"herzlich\", \"herzlich\", \"herzlichen\", \"herzlichen\", \"herzlichen\", \"herzlichen\", \"herzlichen\", \"herzzentrum\", \"herzzentrum\", \"herzzentrum\", \"heute\", \"heute\", \"heute\", \"heute\", \"heute\", \"hierzu\", \"hierzu\", \"hilfe\", \"hilfe\", \"hilfe\", \"hilfe\", \"hilfe\", \"hilfestellungen\", \"hilfsbereit\", \"hilfsbereit\", \"hilfsbereit\", \"hilfsbereit\", \"hilfsbereit\", \"hilfsbereiten\", \"hilfsbereiten\", \"hilfsbereiten\", \"hoffmann\", \"hoffmann\", \"h\\u00e4tte\", \"h\\u00e4tte\", \"h\\u00e4tte\", \"h\\u00e4tte\", \"h\\u00e4tte\", \"h\\u00f6chste\", \"h\\u00f6chste\", \"ibuprofen\", \"immer\", \"immer\", \"immer\", \"immer\", \"immer\", \"info\", \"info\", \"info\", \"info\", \"infusion\", \"infusion\", \"infusion\", \"infusion\", \"its\", \"its\", \"its\", \"its\", \"its\", \"jahrzehnte\", \"jederzeit\", \"jederzeit\", \"jederzeit\", \"jederzeit\", \"jederzeit\", \"jedoch\", \"jedoch\", \"jedoch\", \"jedoch\", \"jedoch\", \"jessica\", \"johannes\", \"kam\", \"kam\", \"kam\", \"kam\", \"kam\", \"katastrophe\", \"katastrophe\", \"katastrophe\", \"katastrophe\", \"katastrophe\", \"katja\", \"kenntnis\", \"klinik\", \"klinik\", \"klinik\", \"klinik\", \"klinik\", \"klinikpersonal\", \"klinikpersonal\", \"klinikpersonal\", \"knappe\", \"kompetent\", \"kompetent\", \"kompetent\", \"kompetent\", \"kompetent\", \"kompetente\", \"kompetente\", \"kompetente\", \"kompetente\", \"kompetente\", \"konnte\", \"konnte\", \"konnte\", \"konnte\", \"konnte\", \"konzept\", \"konzept\", \"konzept\", \"konzept\", \"konzept\", \"koordination\", \"krankenbett\", \"krankenhaus\", \"krankenhaus\", \"krankenhaus\", \"krankenhaus\", \"krankenhaus\", \"kritisch\", \"kritischen\", \"kr\\u00e4ften\", \"kr\\u00fccken\", \"kuchen\", \"kuchen\", \"kuchen\", \"kuchen\", \"kuchen\", \"k\\u00fchlschrank\", \"k\\u00fcnstliche\", \"k\\u00fcnstliche\", \"lassen\", \"lassen\", \"lassen\", \"lassen\", \"lassen\", \"leben\", \"leben\", \"leben\", \"leben\", \"leben\", \"leider\", \"leider\", \"leider\", \"leider\", \"leider\", \"lernen\", \"lernen\", \"lernen\", \"lernen\", \"lernen\", \"lob\", \"lob\", \"lob\", \"lob\", \"lob\", \"lockere\", \"l\\u00f6sungsorientiert\", \"mal\", \"mal\", \"mal\", \"mal\", \"mal\", \"mehr\", \"mehr\", \"mehr\", \"mehr\", \"mehr\", \"meinte\", \"meinte\", \"meinte\", \"meinte\", \"meinte\", \"meistern\", \"meistern\", \"meistern\", \"menschen\", \"menschen\", \"menschen\", \"menschen\", \"menschen\", \"mental\", \"minuten\", \"minuten\", \"minuten\", \"minuten\", \"minuten\", \"mitarbeit\", \"mitpatienten\", \"mitpatienten\", \"mitpatienten\", \"mitpatienten\", \"mitpatienten\", \"mittagessen\", \"mittagessen\", \"mittagessen\", \"mittagessen\", \"mittagessen\", \"mobil\", \"mobil\", \"modernisiert\", \"mutter\", \"mutter\", \"mutter\", \"mutter\", \"mutter\", \"m\\u00f6chte\", \"m\\u00f6chte\", \"m\\u00f6chte\", \"m\\u00f6chte\", \"m\\u00f6chte\", \"nachfrage\", \"nachfrage\", \"nachfrage\", \"nachfrage\", \"nachfrage\", \"nachtwache\", \"nan\", \"narben\", \"nase\", \"nase\", \"nase\", \"nase\", \"nase\", \"nat\\u00fcrlich\", \"nat\\u00fcrlich\", \"nat\\u00fcrlich\", \"nat\\u00fcrlich\", \"nat\\u00fcrlich\", \"nett\", \"nett\", \"nett\", \"nett\", \"nett\", \"nie\", \"nie\", \"nie\", \"nie\", \"nie\", \"niemand\", \"niemand\", \"niemand\", \"niemand\", \"niemand\", \"notaufnahme\", \"notaufnahme\", \"notaufnahme\", \"notaufnahme\", \"notaufnahme\", \"notfallambulanz\", \"notfallambulanz\", \"notfallambulanz\", \"notfallambulanz\", \"notfallambulanz\", \"obwohl\", \"obwohl\", \"obwohl\", \"obwohl\", \"obwohl\", \"offenes\", \"offenes\", \"offenes\", \"offenes\", \"offenes\", \"ohr\", \"ohr\", \"ohr\", \"ohr\", \"ohr\", \"operativen\", \"operiert\", \"operiert\", \"operiert\", \"operiert\", \"operiert\", \"opfer\", \"opfer\", \"organisierte\", \"organisierte\", \"organisiertes\", \"patienten\", \"patienten\", \"patienten\", \"patienten\", \"patienten\", \"personal\", \"personal\", \"personal\", \"personal\", \"personal\", \"potsdam\", \"potsdam\", \"potsdam\", \"praxisteam\", \"prinzip\", \"privatpatient\", \"privatpatient\", \"privatpatient\", \"pro\", \"pro\", \"pro\", \"pro\", \"pro\", \"probleme\", \"probleme\", \"probleme\", \"probleme\", \"probleme\", \"profis\", \"psychiatrischen\", \"psychiatrischen\", \"psychiatrischen\", \"psychiatrischen\", \"psychische\", \"psychische\", \"psychische\", \"psychische\", \"psychische\", \"psychologen\", \"psychologen\", \"psychologen\", \"psychologen\", \"psychologen\", \"psychosomatische\", \"reha\", \"reha\", \"reha\", \"reha\", \"reha\", \"rehaklinik\", \"rehaklinik\", \"rehaklinik\", \"rehaklinik\", \"rehaklinik\", \"reibungslos\", \"reibungslos\", \"reibungslos\", \"reibungslos\", \"reibungslos\", \"restliche\", \"restliche\", \"restliche\", \"restliche\", \"retten\", \"retten\", \"rettungssanit\\u00e4ter\", \"rundum\", \"rundum\", \"rundum\", \"rundum\", \"rundum\", \"r\\u00f6ntgenbilder\", \"sagen\", \"sagen\", \"sagen\", \"sagen\", \"sagen\", \"sagte\", \"sagte\", \"sagte\", \"sagte\", \"sagte\", \"sagten\", \"sagten\", \"sagten\", \"schande\", \"schande\", \"schande\", \"scheiben\", \"schichten\", \"schlauch\", \"schlie\\u00dfung\", \"schlucken\", \"schlucken\", \"schmackhaftes\", \"schmerzen\", \"schmerzen\", \"schmerzen\", \"schmerzen\", \"schmerzen\", \"schnitt\", \"schon\", \"schon\", \"schon\", \"schon\", \"schon\", \"schulmedizin\", \"schwanger\", \"schwanger\", \"schwarz\", \"schwester\", \"schwester\", \"schwester\", \"schwester\", \"schwester\", \"schwestern\", \"schwestern\", \"schwestern\", \"schwestern\", \"schwestern\", \"schwimmbad\", \"schwimmbad\", \"schwimmbad\", \"schwimmbad\", \"schwimmbad\", \"sch\\u00e4mt\", \"sch\\u00f6nem\", \"segen\", \"sei\", \"sei\", \"sei\", \"sei\", \"sei\", \"sensationell\", \"solle\", \"solle\", \"solle\", \"solle\", \"solle\", \"sozialarbeiterin\", \"sozialarbeiterin\", \"sozialarbeiterin\", \"sozialarbeiterin\", \"spritze\", \"spritze\", \"sprunggelenk\", \"sprunggelenk\", \"sp\\u00e4ter\", \"sp\\u00e4ter\", \"sp\\u00e4ter\", \"sp\\u00e4ter\", \"sp\\u00e4ter\", \"starken\", \"starken\", \"starken\", \"starken\", \"starken\", \"starten\", \"station\", \"station\", \"station\", \"station\", \"station\", \"sterben\", \"sterben\", \"sterben\", \"sterben\", \"stern\", \"stern\", \"stern\", \"stern\", \"stern\", \"strukturiert\", \"strukturiert\", \"strukturiert\", \"strukturiert\", \"studium\", \"stunde\", \"stunde\", \"stunde\", \"stunde\", \"stunde\", \"stunden\", \"stunden\", \"stunden\", \"stunden\", \"stunden\", \"super\", \"super\", \"super\", \"super\", \"super\", \"sympathischen\", \"tag\", \"tag\", \"tag\", \"tag\", \"tag\", \"tagesklinik\", \"tagesklinik\", \"tagesklinik\", \"tagesklinik\", \"tagesklinik\", \"tasche\", \"tasche\", \"taxi\", \"taxi\", \"team\", \"team\", \"team\", \"team\", \"team\", \"tep\", \"tep\", \"tep\", \"termin\", \"termin\", \"termin\", \"termin\", \"termin\", \"themen\", \"themen\", \"themen\", \"themen\", \"themen\", \"therapeuten\", \"therapeuten\", \"therapeuten\", \"therapeuten\", \"therapeuten\", \"therapeutenteam\", \"therapie\", \"therapie\", \"therapie\", \"therapie\", \"therapie\", \"therapien\", \"therapien\", \"therapien\", \"therapien\", \"therapien\", \"tolles\", \"tolles\", \"tolles\", \"tolles\", \"tolles\", \"uhr\", \"uhr\", \"uhr\", \"uhr\", \"uhr\", \"ultraschall\", \"ultraschall\", \"ultraschall\", \"ultraschall\", \"umsichtig\", \"umsichtig\", \"unangenehmes\", \"uneingeschr\\u00e4nkt\", \"uneingeschr\\u00e4nkt\", \"uneingeschr\\u00e4nkt\", \"uneingeschr\\u00e4nkt\", \"uneingeschr\\u00e4nkt\", \"unfreundlich\", \"unfreundlich\", \"unfreundlich\", \"unfreundlich\", \"unfreundlich\", \"unh\\u00f6fliche\", \"unkomplizierte\", \"unn\\u00f6tigen\", \"unterschrift\", \"vati\", \"vati\", \"verdammt\", \"vergabe\", \"verlegen\", \"vermisse\", \"vermisse\", \"vernachl\\u00e4ssigt\", \"versprochene\", \"vertrauensvoll\", \"vertrauensvoll\", \"verwandte\", \"verwandte\", \"viele\", \"viele\", \"viele\", \"viele\", \"viele\", \"vielen\", \"vielen\", \"vielen\", \"vielen\", \"vielen\", \"vorbereitungen\", \"vorgestern\", \"vormittag\", \"vormittag\", \"wald\", \"wald\", \"wald\", \"wald\", \"wald\", \"wars\", \"wars\", \"warten\", \"warten\", \"warten\", \"warten\", \"warten\", \"warteraum\", \"wartezimmer\", \"wartezimmer\", \"wartezimmer\", \"wartezimmer\", \"wartezimmer\", \"warum\", \"warum\", \"warum\", \"warum\", \"warum\", \"website\", \"website\", \"wegen\", \"wegen\", \"wegen\", \"wegen\", \"wegen\", \"weiterbehandlung\", \"weiterempfehlen\", \"weiterempfehlen\", \"weiterempfehlen\", \"weiterempfehlen\", \"weiterempfehlen\", \"weiterempfehlung\", \"weiterempfehlung\", \"weiterempfehlung\", \"weiterempfehlung\", \"wer\", \"wer\", \"wer\", \"wer\", \"wer\", \"werdet\", \"werk\", \"werk\", \"wirklich\", \"wirklich\", \"wirklich\", \"wirklich\", \"wirklich\", \"wlan\", \"wlan\", \"wlan\", \"wlan\", \"wlan\", \"woche\", \"woche\", \"woche\", \"woche\", \"woche\", \"wochen\", \"wochen\", \"wochen\", \"wochen\", \"wochen\", \"wohlgemerkt\", \"wolf\", \"wundversorgung\", \"wurde\", \"wurde\", \"wurde\", \"wurde\", \"wurde\", \"wurden\", \"wurden\", \"wurden\", \"wurden\", \"wurden\", \"wut\", \"w\\u00e4re\", \"w\\u00e4re\", \"w\\u00e4re\", \"w\\u00e4re\", \"w\\u00e4re\", \"w\\u00fctend\", \"w\\u00fctend\", \"w\\u00fctend\", \"zahnarzt\", \"zahnarzt\", \"zeit\", \"zeit\", \"zeit\", \"zeit\", \"zeit\", \"zeitweise\", \"zimmer\", \"zimmer\", \"zimmer\", \"zimmer\", \"zimmer\", \"zufrieden\", \"zufrieden\", \"zufrieden\", \"zufrieden\", \"zufrieden\", \"zuvorkommende\", \"z\\u00e4hne\", \"z\\u00e4hne\", \"\\u00e4rzte\", \"\\u00e4rzte\", \"\\u00e4rzte\", \"\\u00e4rzte\", \"\\u00e4rzte\", \"\\u00e4rzteschaft\", \"\\u00e4rztin\", \"\\u00e4rztin\", \"\\u00e4rztin\", \"\\u00e4rztin\", \"\\u00e4rztin\", \"\\u00fcberlastung\", \"\\u00fcberlastung\", \"\\u00fcberlastung\", \"\\u00fcberlebt\", \"\\u00fcberweisung\", \"\\u00fcberweisung\", \"\\u00fcberweisung\", \"\\u00fcberweisung\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 1, 5, 3, 4]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el50031379722601265284183371677\", ldavis_el50031379722601265284183371677_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el50031379722601265284183371677\", ldavis_el50031379722601265284183371677_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el50031379722601265284183371677\", ldavis_el50031379722601265284183371677_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ÜBERARBEITET:"
      ],
      "metadata": {
        "id": "QT8CWsL0OJHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Bereinigt den Text, entfernt Sonderzeichen und Stoppwörter.\"\"\"\n",
        "    text = re.sub(r'[^\\w\\s]', '', str(text))\n",
        "    text = text.lower()\n",
        "    tokens = text.split()\n",
        "    stop_words = set(stopwords.words('german'))\n",
        "    tokens = [token for token in tokens if token not in stop_words and len(token) > 2]\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def prepare_corpus(processed_docs):\n",
        "    \"\"\"Erstellt ein Gensim-Dictionary und Corpus.\"\"\"\n",
        "    dictionary = corpora.Dictionary(processed_docs)\n",
        "    corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "    return dictionary, corpus\n",
        "\n",
        "\n",
        "def train_lda(corpus, dictionary, num_topics=5, passes=15, iterations=400, eval_every=None):\n",
        "    \"\"\"Trainiert das LDA-Modell.\"\"\"\n",
        "    lda_model = LdaModel(\n",
        "        corpus,\n",
        "        num_topics=num_topics,\n",
        "        id2word=dictionary,\n",
        "        random_state=42,\n",
        "        passes=passes,\n",
        "        iterations=iterations,\n",
        "        eval_every=eval_every\n",
        "    )\n",
        "    return lda_model\n",
        "\n",
        "\n",
        "def evaluate_model(lda_model, corpus, dictionary, processed_docs):\n",
        "    \"\"\"Berechnet den Coherence Score.\"\"\"\n",
        "    coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_docs, dictionary=dictionary,\n",
        "                                          coherence='c_v')\n",
        "    coherence = coherence_model_lda.get_coherence()\n",
        "    print('\\nCoherence Score: ', coherence)\n",
        "    return coherence\n",
        "\n",
        "\n",
        "def display_topics(lda_model, num_words=10):\n",
        "    \"\"\"Gibt die Top-Wörter pro Topic aus.\"\"\"\n",
        "    for idx, topic in lda_model.print_topics(-1, num_words=num_words):\n",
        "        print(f'Topic: {idx} \\nWords: {topic}')\n",
        "\n",
        "\n",
        "def visualize_lda(lda_model, corpus, dictionary):\n",
        "    \"\"\"Erzeugt eine interaktive LDA-Visualisierung.\"\"\"\n",
        "    vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)\n",
        "    pyLDAvis.display(vis)\n",
        "\n",
        "\n",
        "def remove_top_words(processed_docs, top_words):\n",
        "    \"\"\"Entfernt die häufigsten Wörter aus den Dokumenten.\"\"\"\n",
        "    processed_docs = [[word for word in doc if word not in top_words] for doc in processed_docs]\n",
        "    return processed_docs\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Hauptfunktion zum Ausführen der LDA-Analyse.\"\"\"\n",
        "    # Daten laden\n",
        "    df = pd.read_csv(r'/content/06_data_raw_no_doubles.csv')\n",
        "    review_column = 'rezension'\n",
        "    rating_column = 'bewertung'\n",
        "\n",
        "    # Fehlermeldung, wenn die Spalte nicht gefunden wird\n",
        "    if review_column not in df.columns or rating_column not in df.columns:\n",
        "        raise ValueError(f\"Column '{review_column}' or '{rating_column}' not found in DataFrame.\")\n",
        "\n",
        "    # Filtern der Daten nach positiven und negativen Bewertungen\n",
        "    positive_df = df[df[rating_column] >= 4]\n",
        "    negative_df = df[df[rating_column] <= 2]\n",
        "\n",
        "    # LDA für positive Bewertungen\n",
        "    print(\"Starte LDA für positive Bewertungen:\")\n",
        "    positive_reviews = positive_df[review_column].astype(str)\n",
        "    processed_positive = positive_reviews.map(preprocess_text)\n",
        "    dictionary_positive, corpus_positive = prepare_corpus(processed_positive)\n",
        "\n",
        "    # Ermitteln der optimalen Anzahl an Topics (optional)\n",
        "    # Um eine optimale Anzahl an Topics zu ermitteln, kann man den Coherence Score für verschiedene\n",
        "    # Topic-Anzahlen berechnen und diejenige mit dem höchsten Score auswählen.\n",
        "\n",
        "    num_topics_positive = 5\n",
        "    lda_model_positive = train_lda(corpus_positive, dictionary_positive, num_topics=num_topics_positive)\n",
        "    coherence_score_positive = evaluate_model(lda_model_positive, corpus_positive, dictionary_positive,\n",
        "                                               processed_positive)\n",
        "    display_topics(lda_model_positive)\n",
        "    visualize_lda(lda_model_positive, corpus_positive, dictionary_positive)\n",
        "\n",
        "    # Manuelles Entfernen von Wörtern\n",
        "    words_to_remove = input(\"Geben Sie Wörter an, die aus den Topics entfernt werden sollen (getrennt durch Komma): \").split(',')\n",
        "    words_to_remove = [word.strip() for word in words_to_remove]  # Leerzeichen entfernen\n",
        "    processed_positive = remove_top_words(processed_positive, words_to_remove)\n",
        "\n",
        "    # Erneutes Trainieren des LDA-Modells mit bereinigten Daten\n",
        "    dictionary_positive, corpus_positive = prepare_corpus(processed_positive)\n",
        "    lda_model_positive = train_lda(corpus_positive, dictionary_positive, num_topics=num_topics_positive)\n",
        "    coherence_score_positive = evaluate_model(lda_model_positive, corpus_positive, dictionary_positive,\n",
        "                                               processed_positive)\n",
        "    display_topics(lda_model_positive)\n",
        "    visualize_lda(lda_model_positive, corpus_positive, dictionary_positive)\n",
        "\n",
        "    # LDA für negative Bewertungen\n",
        "    print(\"\\nStarte LDA für negative Bewertungen:\")\n",
        "    negative_reviews = negative_df[review_column].astype(str)\n",
        "    processed_negative = negative_reviews.map(preprocess_text)\n",
        "    dictionary_negative, corpus_negative = prepare_corpus(processed_negative)\n",
        "\n",
        "    num_topics_negative = 5\n",
        "    lda_model_negative = train_lda(corpus_negative, dictionary_negative, num_topics=num_topics_negative)\n",
        "    coherence_score_negative = evaluate_model(lda_model_negative, corpus_negative, dictionary_negative,\n",
        "                                               processed_negative)\n",
        "    display_topics(lda_model_negative)\n",
        "    visualize_lda(lda_model_negative, corpus_negative, dictionary_negative)\n",
        "\n",
        "    # Manuelles Entfernen von Wörtern\n",
        "    words_to_remove = input(\"Geben Sie Wörter an, die aus den Topics entfernt werden sollen (getrennt durch Komma): \").split(',')\n",
        "    words_to_remove = [word.strip() for word in words_to_remove]  # Leerzeichen entfernen\n",
        "    processed_negative = remove_top_words(processed_negative, words_to_remove)\n",
        "\n",
        "    # Erneutes Trainieren des LDA-Modells mit bereinigten Daten\n",
        "    dictionary_negative, corpus_negative = prepare_corpus(processed_negative)\n",
        "    lda_model_negative = train_lda(corpus_negative, dictionary_negative, num_topics=num_topics_negative)\n",
        "    coherence_score_negative = evaluate_model(lda_model_negative, corpus_negative, dictionary_negative,\n",
        "                                               processed_negative)\n",
        "    display_topics(lda_model_negative)\n",
        "    visualize_lda(lda_model_negative, corpus_negative, dictionary_negative)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "O84MXLFuOKZ9",
        "outputId": "9c171812-dfa2-45e7-cd03-ec3fda9632e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starte LDA für positive Bewertungen:\n",
            "\n",
            "Coherence Score:  0.5356109172096308\n",
            "Topic: 0 \n",
            "Words: 0.019*\"gut\" + 0.017*\"wurde\" + 0.014*\"freundlich\" + 0.011*\"station\" + 0.011*\"krankenhaus\" + 0.011*\"super\" + 0.010*\"ärzte\" + 0.009*\"dank\" + 0.009*\"personal\" + 0.009*\"immer\"\n",
            "Topic: 1 \n",
            "Words: 0.010*\"nan\" + 0.002*\"the\" + 0.002*\"and\" + 0.001*\"bus\" + 0.001*\"freie\" + 0.001*\"moegelin\" + 0.001*\"fürsorglichen\" + 0.001*\"weiterbehandlung\" + 0.001*\"passen\" + 0.001*\"vati\"\n",
            "Topic: 2 \n",
            "Words: 0.016*\"team\" + 0.015*\"klinik\" + 0.012*\"dank\" + 0.008*\"zeit\" + 0.008*\"gut\" + 0.007*\"möchte\" + 0.007*\"vielen\" + 0.007*\"frau\" + 0.006*\"gesamte\" + 0.006*\"betreuung\"\n",
            "Topic: 3 \n",
            "Words: 0.014*\"klinik\" + 0.010*\"immer\" + 0.010*\"gut\" + 0.010*\"essen\" + 0.009*\"gibt\" + 0.007*\"patienten\" + 0.007*\"therapeuten\" + 0.007*\"zimmer\" + 0.006*\"wochen\" + 0.006*\"mal\"\n",
            "Topic: 4 \n",
            "Words: 0.019*\"hebammen\" + 0.019*\"geburt\" + 0.010*\"welt\" + 0.008*\"kind\" + 0.008*\"kreißsaal\" + 0.008*\"hebamme\" + 0.005*\"entbunden\" + 0.005*\"tochter\" + 0.004*\"kaiserschnitt\" + 0.004*\"baby\"\n",
            "Geben Sie Wörter an, die aus den Topics entfernt werden sollen (getrennt durch Komma): möchte\n",
            "\n",
            "Coherence Score:  0.41662499416259935\n",
            "Topic: 0 \n",
            "Words: 0.019*\"klinik\" + 0.014*\"gut\" + 0.011*\"immer\" + 0.008*\"essen\" + 0.008*\"patienten\" + 0.007*\"gibt\" + 0.007*\"therapeuten\" + 0.007*\"zeit\" + 0.006*\"wochen\" + 0.006*\"personal\"\n",
            "Topic: 1 \n",
            "Words: 0.015*\"team\" + 0.010*\"betreuung\" + 0.007*\"gesamte\" + 0.007*\"dank\" + 0.006*\"frau\" + 0.005*\"besonders\" + 0.005*\"behandlung\" + 0.005*\"gesamten\" + 0.005*\"arbeit\" + 0.005*\"dankbar\"\n",
            "Topic: 2 \n",
            "Words: 0.002*\"therapieangebot\" + 0.002*\"insbesondere\" + 0.002*\"therapie\" + 0.002*\"musik\" + 0.002*\"hund\" + 0.001*\"herr\" + 0.001*\"frau\" + 0.001*\"lage\" + 0.001*\"möglichkeit\" + 0.001*\"sicht\"\n",
            "Topic: 3 \n",
            "Words: 0.019*\"wurde\" + 0.018*\"gut\" + 0.014*\"freundlich\" + 0.011*\"krankenhaus\" + 0.011*\"dank\" + 0.011*\"station\" + 0.009*\"team\" + 0.009*\"ärzte\" + 0.009*\"super\" + 0.008*\"klinik\"\n",
            "Topic: 4 \n",
            "Words: 0.009*\"immer\" + 0.008*\"dank\" + 0.008*\"hebammen\" + 0.008*\"geburt\" + 0.008*\"frau\" + 0.006*\"kind\" + 0.006*\"danke\" + 0.006*\"team\" + 0.006*\"zeit\" + 0.006*\"tochter\"\n",
            "\n",
            "Starte LDA für negative Bewertungen:\n",
            "\n",
            "Coherence Score:  0.3073100796164552\n",
            "Topic: 0 \n",
            "Words: 0.016*\"wurde\" + 0.006*\"leider\" + 0.006*\"klinik\" + 0.005*\"mehr\" + 0.004*\"mal\" + 0.004*\"station\" + 0.003*\"patienten\" + 0.003*\"immer\" + 0.003*\"gut\" + 0.003*\"einfach\"\n",
            "Topic: 1 \n",
            "Words: 0.014*\"patienten\" + 0.011*\"klinik\" + 0.006*\"mehr\" + 0.006*\"menschen\" + 0.006*\"wurde\" + 0.005*\"mal\" + 0.005*\"einfach\" + 0.005*\"ärzte\" + 0.004*\"leider\" + 0.004*\"wirklich\"\n",
            "Topic: 2 \n",
            "Words: 0.014*\"wurde\" + 0.012*\"stunden\" + 0.011*\"krankenhaus\" + 0.010*\"notaufnahme\" + 0.009*\"termin\" + 0.009*\"warten\" + 0.008*\"arzt\" + 0.008*\"uhr\" + 0.005*\"schmerzen\" + 0.005*\"mal\"\n",
            "Topic: 3 \n",
            "Words: 0.017*\"wurde\" + 0.008*\"klinik\" + 0.006*\"mal\" + 0.006*\"mutter\" + 0.005*\"leider\" + 0.005*\"konnte\" + 0.005*\"mehr\" + 0.004*\"krankenhaus\" + 0.004*\"schon\" + 0.004*\"gut\"\n",
            "Topic: 4 \n",
            "Words: 0.016*\"wurde\" + 0.011*\"krankenhaus\" + 0.006*\"arzt\" + 0.005*\"notaufnahme\" + 0.005*\"station\" + 0.005*\"mutter\" + 0.005*\"mal\" + 0.005*\"einfach\" + 0.005*\"schmerzen\" + 0.004*\"tag\"\n",
            "Geben Sie Wörter an, die aus den Topics entfernt werden sollen (getrennt durch Komma): mal, konnte, mehr\n",
            "\n",
            "Coherence Score:  0.35431859354075396\n",
            "Topic: 0 \n",
            "Words: 0.021*\"wurde\" + 0.010*\"krankenhaus\" + 0.007*\"arzt\" + 0.006*\"notaufnahme\" + 0.005*\"leider\" + 0.005*\"patienten\" + 0.005*\"schmerzen\" + 0.005*\"klinik\" + 0.005*\"stunden\" + 0.005*\"mutter\"\n",
            "Topic: 1 \n",
            "Words: 0.011*\"klinik\" + 0.010*\"wurde\" + 0.010*\"patienten\" + 0.005*\"leider\" + 0.004*\"immer\" + 0.004*\"personal\" + 0.003*\"wochen\" + 0.003*\"gibt\" + 0.003*\"gut\" + 0.003*\"schon\"\n",
            "Topic: 2 \n",
            "Words: 0.010*\"patienten\" + 0.007*\"einfach\" + 0.007*\"klinik\" + 0.005*\"krankenhaus\" + 0.005*\"geht\" + 0.004*\"menschen\" + 0.004*\"personal\" + 0.004*\"ärzte\" + 0.004*\"schon\" + 0.004*\"kind\"\n",
            "Topic: 3 \n",
            "Words: 0.010*\"wurde\" + 0.007*\"zimmer\" + 0.006*\"patienten\" + 0.005*\"klinik\" + 0.005*\"schon\" + 0.005*\"station\" + 0.004*\"stunden\" + 0.004*\"essen\" + 0.004*\"personal\" + 0.004*\"krankenhaus\"\n",
            "Topic: 4 \n",
            "Words: 0.001*\"mrt\" + 0.001*\"nummer\" + 0.001*\"verzögerungen\" + 0.001*\"rechten\" + 0.001*\"kbokinderzentrum\" + 0.001*\"damals\" + 0.001*\"röntgen\" + 0.001*\"assistenzarzt\" + 0.001*\"loos\" + 0.001*\"ergebnis\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Überarbeitung 2"
      ],
      "metadata": {
        "id": "hgDnUXvmUMt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(r'/content/06_data_raw_no_doubles.csv')\n",
        "review_column = 'rezension'\n",
        "if review_column not in df.columns:\n",
        "    raise ValueError(f\"Column '{review_column}' not found in DataFrame.\")\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', str(text))\n",
        "    text = text.lower()\n",
        "    tokens = text.split()\n",
        "    stop_words = set(stopwords.words('german'))\n",
        "    tokens = [token for token in tokens if token not in stop_words and len(token) > 2]\n",
        "    return tokens\n",
        "\n",
        "def prepare_corpus(processed_docs): #Gensim-dictionary und Gensim-Korpus\n",
        "    dictionary = corpora.Dictionary(processed_docs)\n",
        "    corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "    return dictionary, corpus\n",
        "\n",
        "# n = k, festlegen!! Iteratives Trainieren des LDA Modells\n",
        "def train_lda(corpus, dictionary, num_topics=5, passes=15, iterations=400, eval_every=None):\n",
        "    lda_model = LdaModel(\n",
        "        corpus,\n",
        "        num_topics=num_topics,\n",
        "        id2word=dictionary,\n",
        "        random_state=42,\n",
        "        passes=passes,\n",
        "        iterations=iterations,\n",
        "        eval_every=eval_every\n",
        "    )\n",
        "    return lda_model\n",
        "\n",
        "# Coherence-Score; je höher, desto 'bessere' Topics\n",
        "def evaluate_model(lda_model, corpus, dictionary, processed_docs):\n",
        "    \"\"\"Berechnet den Coherence Score.\"\"\"\n",
        "    coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_docs, dictionary=dictionary,\n",
        "                                          coherence='c_v')\n",
        "    coherence = coherence_model_lda.get_coherence()\n",
        "    print('\\nCoherence Score: ', coherence)\n",
        "    return coherence\n",
        "\n",
        "# erste 10 topics anzeigen\n",
        "def display_topics(lda_model, num_words=10):\n",
        "    \"\"\"Gibt die Top-Wörter pro Topic aus.\"\"\"\n",
        "    for idx, topic in lda_model.print_topics(-1, num_words=num_words):\n",
        "        print(f'Topic: {idx} \\nWords: {topic}')\n",
        "\n",
        "# erste Visualisierung\n",
        "def visualize_lda(lda_model, corpus, dictionary):\n",
        "    \"\"\"Erzeugt eine interaktive LDA-Visualisierung.\"\"\"\n",
        "    vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)\n",
        "    pyLDAvis.display(vis)\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Hauptfunktion zum Ausführen der LDA-Analyse.\"\"\"\n",
        "    # Daten laden\n",
        "    df = pd.read_csv(r'/content/06_data_raw_no_doubles.csv')\n",
        "    review_column = 'rezension'\n",
        "    rating_column = 'bewertung'\n",
        "\n",
        "    # Fehlermeldung, wenn die Spalte nicht gefunden wird\n",
        "    if review_column not in df.columns or rating_column not in df.columns:\n",
        "        raise ValueError(f\"Column '{review_column}' or '{rating_column}' not found in DataFrame.\")\n",
        "\n",
        "    # Filtern der Daten nach positiven und negativen Bewertungen\n",
        "    positive_df = df[df[rating_column] >= 4]\n",
        "    negative_df = df[df[rating_column] <= 2]\n",
        "\n",
        "\n",
        "    # LDA für positive Bewertungen\n",
        "    print(\"Starte LDA für positive Bewertungen:\")\n",
        "    positive_reviews = positive_df[review_column].astype(str)\n",
        "    processed_positive = positive_reviews.map(preprocess_text)\n",
        "    dictionary_positive, corpus_positive = prepare_corpus(processed_positive)\n",
        "\n",
        "    num_topics_positive = 5\n",
        "    lda_model_positive = train_lda(corpus_positive, dictionary_positive, num_topics=num_topics_positive)\n",
        "    coherence_score_positive = evaluate_model(lda_model_positive, corpus_positive, dictionary_positive,\n",
        "                                               processed_positive)\n",
        "    display_topics(lda_model_positive)\n",
        "    visualize_lda(lda_model_positive, corpus_positive, dictionary_positive)\n",
        "\n",
        "\n",
        "    # LDA für negative Bewertungen\n",
        "    print(\"\\nStarte LDA für negative Bewertungen:\")\n",
        "    negative_reviews = negative_df[review_column].astype(str)\n",
        "    processed_negative = negative_reviews.map(preprocess_text)\n",
        "    dictionary_negative, corpus_negative = prepare_corpus(processed_negative)\n",
        "\n",
        "    num_topics_negative = 5\n",
        "    lda_model_negative = train_lda(corpus_negative, dictionary_negative, num_topics=num_topics_negative)\n",
        "    coherence_score_negative = evaluate_model(lda_model_negative, corpus_negative, dictionary_negative,\n",
        "                                               processed_negative)\n",
        "    display_topics(lda_model_negative)\n",
        "    visualize_lda(lda_model_negative, corpus_negative, dictionary_negative)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "# Visualisierung mit pyLDAvis\n",
        "vis_neg = pyLDAvis.gensim_models.prepare(lda_model_negative, corpus, dictionary) # prepare aus gensim_models\n",
        "pyLDAvis.display(vis_neg)\n",
        "\n",
        "\n",
        "# Visualisierung mit pyLDAvis\n",
        "vis_pos = pyLDAvis.gensim_models.prepare(lda_model_positive, corpus, dictionary) # prepare aus gensim_models\n",
        "pyLDAvis.display(vis_pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "Ka29wvyCUN63",
        "outputId": "d5a2749f-aabf-41d8-ca4e-c34bf485787c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starte LDA für positive Bewertungen:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'corpora' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-04ff16787248>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-04ff16787248>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mpositive_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositive_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreview_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mprocessed_positive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositive_reviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mdictionary_positive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_positive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_positive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mnum_topics_positive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-04ff16787248>\u001b[0m in \u001b[0;36mprepare_corpus\u001b[0;34m(processed_docs)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepare_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#Gensim-dictionary und Gensim-Korpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocessed_docs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'corpora' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', str(text))\n",
        "    text = text.lower()\n",
        "    tokens = text.split()\n",
        "    stop_words = set(stopwords.words('german'))\n",
        "    tokens = [token for token in tokens if token not in stop_words and len(token) > 2]\n",
        "    return tokens\n",
        "\n",
        "def prepare_corpus(processed_docs):\n",
        "    dictionary = corpora.Dictionary(processed_docs)\n",
        "    corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "    return dictionary, corpus\n",
        "\n",
        "def train_lda(corpus, dictionary, num_topics=5, passes=15, iterations=400, eval_every=None):\n",
        "    lda_model = LdaModel(\n",
        "        corpus,\n",
        "        num_topics=num_topics,\n",
        "        id2word=dictionary,\n",
        "        random_state=42,\n",
        "        passes=passes,\n",
        "        iterations=iterations,\n",
        "        eval_every=eval_every\n",
        "    )\n",
        "    return lda_model\n",
        "\n",
        "def evaluate_model(lda_model, corpus, dictionary, processed_docs):\n",
        "    coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_docs, dictionary=dictionary,\n",
        "                                          coherence='c_v')\n",
        "    coherence = coherence_model_lda.get_coherence()\n",
        "    print('\\nCoherence Score: ', coherence)\n",
        "    return coherence\n",
        "\n",
        "def display_topics(lda_model, num_words=10):\n",
        "    for idx, topic in lda_model.print_topics(-1, num_words=num_words):\n",
        "        print(f'Topic: {idx} \\nWords: {topic}')\n",
        "\n",
        "def visualize_lda(lda_model, corpus, dictionary):\n",
        "    vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)\n",
        "    pyLDAvis.display(vis)\n",
        "\n",
        "def main():\n",
        "    df = pd.read_csv(r'/content/06_data_raw_no_doubles.csv')\n",
        "    review_column = 'rezension'\n",
        "    rating_column = 'bewertung'\n",
        "\n",
        "    if review_column not in df.columns or rating_column not in df.columns:\n",
        "        raise ValueError(f\"Column '{review_column}' or '{rating_column}' not found in DataFrame.\")\n",
        "\n",
        "    positive_df = df[df[rating_column] >= 4]\n",
        "    negative_df = df[df[rating_column] <= 2]\n",
        "\n",
        "    print(\"Starte LDA für positive Bewertungen:\")\n",
        "    positive_reviews = positive_df[review_column].astype(str)\n",
        "    processed_positive = positive_reviews.map(preprocess_text)\n",
        "    dictionary_positive, corpus_positive = prepare_corpus(processed_positive)\n",
        "\n",
        "    num_topics_positive = 5\n",
        "    lda_model_positive = train_lda(corpus_positive, dictionary_positive, num_topics=num_topics_positive)\n",
        "    coherence_score_positive = evaluate_model(lda_model_positive, corpus_positive, dictionary_positive,\n",
        "                                               processed_positive)\n",
        "    display_topics(lda_model_positive)\n",
        "    visualize_lda(lda_model_positive, corpus_positive, dictionary_positive)\n",
        "\n",
        "    print(\"\\nStarte LDA für negative Bewertungen:\")\n",
        "    negative_reviews = negative_df[review_column].astype(str)\n",
        "    processed_negative = negative_reviews.map(preprocess_text)\n",
        "    dictionary_negative, corpus_negative = prepare_corpus(processed_negative)\n",
        "\n",
        "    num_topics_negative = 5\n",
        "    lda_model_negative = train_lda(corpus_negative, dictionary_negative, num_topics=num_topics_negative)\n",
        "    coherence_score_negative = evaluate_model(lda_model_negative, corpus_negative, dictionary_negative,\n",
        "                                               processed_negative)\n",
        "    display_topics(lda_model_negative)\n",
        "    visualize_lda(lda_model_negative, corpus_negative, dictionary_negative)\n",
        "\n",
        "    # Visualisierung mit pyLDAvis for negative reviews\n",
        "    vis_neg = pyLDAvis.gensim_models.prepare(lda_model_negative, corpus_negative, dictionary_negative)\n",
        "    pyLDAvis.display(vis_neg)\n",
        "\n",
        "    # Visualisierung mit pyLDAvis for positive reviews\n",
        "    vis_pos = pyLDAvis.gensim_models.prepare(lda_model_positive, corpus_positive, dictionary_positive) # prepare aus gensim_models\n",
        "    pyLDAvis.display(vis_pos)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuxWMuGoYO1Y",
        "outputId": "df827f58-8e22-4a85-c415-0297d8a587b1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starte LDA für positive Bewertungen:\n",
            "\n",
            "Coherence Score:  0.5356109172096308\n",
            "Topic: 0 \n",
            "Words: 0.019*\"gut\" + 0.017*\"wurde\" + 0.014*\"freundlich\" + 0.011*\"station\" + 0.011*\"krankenhaus\" + 0.011*\"super\" + 0.010*\"ärzte\" + 0.009*\"dank\" + 0.009*\"personal\" + 0.009*\"immer\"\n",
            "Topic: 1 \n",
            "Words: 0.010*\"nan\" + 0.002*\"the\" + 0.002*\"and\" + 0.001*\"bus\" + 0.001*\"freie\" + 0.001*\"moegelin\" + 0.001*\"fürsorglichen\" + 0.001*\"weiterbehandlung\" + 0.001*\"passen\" + 0.001*\"vati\"\n",
            "Topic: 2 \n",
            "Words: 0.016*\"team\" + 0.015*\"klinik\" + 0.012*\"dank\" + 0.008*\"zeit\" + 0.008*\"gut\" + 0.007*\"möchte\" + 0.007*\"vielen\" + 0.007*\"frau\" + 0.006*\"gesamte\" + 0.006*\"betreuung\"\n",
            "Topic: 3 \n",
            "Words: 0.014*\"klinik\" + 0.010*\"immer\" + 0.010*\"gut\" + 0.010*\"essen\" + 0.009*\"gibt\" + 0.007*\"patienten\" + 0.007*\"therapeuten\" + 0.007*\"zimmer\" + 0.006*\"wochen\" + 0.006*\"mal\"\n",
            "Topic: 4 \n",
            "Words: 0.019*\"hebammen\" + 0.019*\"geburt\" + 0.010*\"welt\" + 0.008*\"kind\" + 0.008*\"kreißsaal\" + 0.008*\"hebamme\" + 0.005*\"entbunden\" + 0.005*\"tochter\" + 0.004*\"kaiserschnitt\" + 0.004*\"baby\"\n",
            "\n",
            "Starte LDA für negative Bewertungen:\n",
            "\n",
            "Coherence Score:  0.3073100796164552\n",
            "Topic: 0 \n",
            "Words: 0.016*\"wurde\" + 0.006*\"leider\" + 0.006*\"klinik\" + 0.005*\"mehr\" + 0.004*\"mal\" + 0.004*\"station\" + 0.003*\"patienten\" + 0.003*\"immer\" + 0.003*\"gut\" + 0.003*\"einfach\"\n",
            "Topic: 1 \n",
            "Words: 0.014*\"patienten\" + 0.011*\"klinik\" + 0.006*\"mehr\" + 0.006*\"menschen\" + 0.006*\"wurde\" + 0.005*\"mal\" + 0.005*\"einfach\" + 0.005*\"ärzte\" + 0.004*\"leider\" + 0.004*\"wirklich\"\n",
            "Topic: 2 \n",
            "Words: 0.014*\"wurde\" + 0.012*\"stunden\" + 0.011*\"krankenhaus\" + 0.010*\"notaufnahme\" + 0.009*\"termin\" + 0.009*\"warten\" + 0.008*\"arzt\" + 0.008*\"uhr\" + 0.005*\"schmerzen\" + 0.005*\"mal\"\n",
            "Topic: 3 \n",
            "Words: 0.017*\"wurde\" + 0.008*\"klinik\" + 0.006*\"mal\" + 0.006*\"mutter\" + 0.005*\"leider\" + 0.005*\"konnte\" + 0.005*\"mehr\" + 0.004*\"krankenhaus\" + 0.004*\"schon\" + 0.004*\"gut\"\n",
            "Topic: 4 \n",
            "Words: 0.016*\"wurde\" + 0.011*\"krankenhaus\" + 0.006*\"arzt\" + 0.005*\"notaufnahme\" + 0.005*\"station\" + 0.005*\"mutter\" + 0.005*\"mal\" + 0.005*\"einfach\" + 0.005*\"schmerzen\" + 0.004*\"tag\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "import pyLDAvis.gensim_models\n",
        "import pyLDAvis\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', str(text))\n",
        "    text = text.lower()\n",
        "    tokens = text.split()\n",
        "    stop_words = set(stopwords.words('german'))\n",
        "    tokens = [token for token in tokens if token not in stop_words and len(token) > 2]\n",
        "    return tokens\n",
        "\n",
        "def prepare_corpus(processed_docs):\n",
        "    dictionary = corpora.Dictionary(processed_docs)\n",
        "    corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "    return dictionary, corpus\n",
        "\n",
        "def train_lda(corpus, dictionary, num_topics=5):\n",
        "    lda_model = LdaModel(corpus, num_topics=num_topics, id2word=dictionary, random_state=42)\n",
        "    return lda_model\n",
        "\n",
        "def evaluate_model(lda_model, corpus, dictionary, processed_docs):\n",
        "    coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_docs, dictionary=dictionary, coherence='c_v')\n",
        "    coherence = coherence_model_lda.get_coherence()\n",
        "    print('\\nCoherence Score: ', coherence)\n",
        "    return coherence\n",
        "\n",
        "def display_topics(lda_model, num_words=10):\n",
        "    for idx, topic in lda_model.print_topics(-1, num_words=num_words):\n",
        "        print(f'Topic: {idx} \\nWords: {topic}')\n",
        "\n",
        "def visualize_lda(lda_model, corpus, dictionary):\n",
        "    vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)\n",
        "    pyLDAvis.display(vis)\n",
        "\n",
        "def main():\n",
        "    df = pd.read_csv(r'/content/06_data_raw_no_doubles.csv')\n",
        "    review_column = 'rezension'\n",
        "    rating_column = 'bewertung'\n",
        "\n",
        "    if review_column not in df.columns or rating_column not in df.columns:\n",
        "        raise ValueError(f\"Column '{review_column}' or '{rating_column}' not found in DataFrame.\")\n",
        "\n",
        "    positive_df = df[df[rating_column] >= 4]\n",
        "    negative_df = df[df[rating_column] <= 2]\n",
        "\n",
        "    print(\"Starte LDA für positive Bewertungen:\")\n",
        "    positive_reviews = positive_df[review_column].astype(str)\n",
        "    processed_positive = positive_reviews.map(preprocess_text)\n",
        "    dictionary_positive, corpus_positive = prepare_corpus(processed_positive)\n",
        "\n",
        "    num_topics_positive = 5\n",
        "    lda_model_positive = train_lda(corpus_positive, dictionary_positive, num_topics=num_topics_positive)\n",
        "    coherence_score_positive = evaluate_model(lda_model_positive, corpus_positive, dictionary_positive,processed_positive)\n",
        "    display_topics(lda_model_positive)\n",
        "    visualize_lda(lda_model_positive, corpus_positive, dictionary_positive)\n",
        "\n",
        "    print(\"\\nStarte LDA für negative Bewertungen:\")\n",
        "    negative_reviews = negative_df[review_column].astype(str)\n",
        "    processed_negative = negative_reviews.map(preprocess_text)\n",
        "    dictionary_negative, corpus_negative = prepare_corpus(processed_negative)\n",
        "\n",
        "    num_topics_negative = 5\n",
        "    lda_model_negative = train_lda(corpus_negative, dictionary_negative, num_topics=num_topics_negative)\n",
        "    coherence_score_negative = evaluate_model(lda_model_negative, corpus_negative, dictionary_negative,processed_negative)\n",
        "    display_topics(lda_model_negative)\n",
        "    visualize_lda(lda_model_negative, corpus_negative, dictionary_negative)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "qQHiMWH0bvzZ",
        "outputId": "8be1c3fc-08c3-4edd-de8c-70c1b8d0b049",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starte LDA für positive Bewertungen:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Coherence Score:  0.40011651397111986\n",
            "Topic: 0 \n",
            "Words: 0.019*\"gut\" + 0.016*\"wurde\" + 0.012*\"freundlich\" + 0.011*\"station\" + 0.010*\"dank\" + 0.009*\"krankenhaus\" + 0.009*\"ärzte\" + 0.008*\"personal\" + 0.008*\"klinik\" + 0.008*\"super\"\n",
            "Topic: 1 \n",
            "Words: 0.007*\"nan\" + 0.006*\"tagesklinik\" + 0.005*\"gut\" + 0.005*\"klinik\" + 0.004*\"super\" + 0.004*\"patienten\" + 0.004*\"zeit\" + 0.004*\"immer\" + 0.004*\"freundlich\" + 0.004*\"danke\"\n",
            "Topic: 2 \n",
            "Words: 0.020*\"klinik\" + 0.012*\"team\" + 0.011*\"gut\" + 0.011*\"wurde\" + 0.008*\"dank\" + 0.007*\"freundlich\" + 0.006*\"zeit\" + 0.006*\"danke\" + 0.006*\"vielen\" + 0.005*\"ärzte\"\n",
            "Topic: 3 \n",
            "Words: 0.014*\"immer\" + 0.011*\"klinik\" + 0.008*\"gut\" + 0.008*\"essen\" + 0.008*\"gibt\" + 0.007*\"patienten\" + 0.006*\"freundlich\" + 0.005*\"zeit\" + 0.005*\"zimmer\" + 0.005*\"mal\"\n",
            "Topic: 4 \n",
            "Words: 0.009*\"dank\" + 0.009*\"möchte\" + 0.007*\"betreuung\" + 0.006*\"zeit\" + 0.006*\"geburt\" + 0.006*\"frau\" + 0.005*\"team\" + 0.005*\"gut\" + 0.005*\"vielen\" + 0.005*\"patienten\"\n",
            "\n",
            "Starte LDA für negative Bewertungen:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Coherence Score:  0.2859322586973052\n",
            "Topic: 0 \n",
            "Words: 0.016*\"wurde\" + 0.007*\"leider\" + 0.006*\"mehr\" + 0.006*\"klinik\" + 0.005*\"mal\" + 0.005*\"stunden\" + 0.004*\"einfach\" + 0.004*\"krankenhaus\" + 0.004*\"station\" + 0.003*\"tag\"\n",
            "Topic: 1 \n",
            "Words: 0.015*\"patienten\" + 0.010*\"klinik\" + 0.009*\"wurde\" + 0.006*\"arzt\" + 0.005*\"mehr\" + 0.005*\"mal\" + 0.005*\"einfach\" + 0.005*\"menschen\" + 0.005*\"ärzte\" + 0.004*\"krankenhaus\"\n",
            "Topic: 2 \n",
            "Words: 0.012*\"wurde\" + 0.008*\"krankenhaus\" + 0.006*\"mehr\" + 0.006*\"termin\" + 0.005*\"patienten\" + 0.004*\"uhr\" + 0.004*\"stunden\" + 0.004*\"warten\" + 0.004*\"notaufnahme\" + 0.004*\"arzt\"\n",
            "Topic: 3 \n",
            "Words: 0.015*\"wurde\" + 0.009*\"klinik\" + 0.008*\"mal\" + 0.006*\"notaufnahme\" + 0.005*\"leider\" + 0.005*\"mutter\" + 0.005*\"mehr\" + 0.005*\"patienten\" + 0.005*\"schon\" + 0.004*\"arzt\"\n",
            "Topic: 4 \n",
            "Words: 0.016*\"wurde\" + 0.009*\"krankenhaus\" + 0.006*\"station\" + 0.005*\"patienten\" + 0.005*\"notaufnahme\" + 0.005*\"einfach\" + 0.004*\"arzt\" + 0.004*\"mal\" + 0.004*\"tag\" + 0.004*\"mehr\"\n"
          ]
        }
      ]
    }
  ]
}