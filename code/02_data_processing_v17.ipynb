{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Abhängigkeiten installieren und Packages laden"
      ],
      "metadata": {
        "id": "4_dqpQXVgm65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install gensim\n",
        "!pip install nltk\n",
        "!pip install regex\n",
        "!pip install numpy\n",
        "!pip install scikit-learn\n",
        "!pip install pyLDAvis\n",
        "!pip install matplotlib\n",
        "\n",
        "!pip install --upgrade numpy\n",
        "!pip install --upgrade scipy\n",
        "!pip install --upgrade gensim\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "import pyLDAvis.gensim_models\n",
        "import pyLDAvis\n",
        "\n",
        "# wenn es nicht läuft runtime neu starten"
      ],
      "metadata": {
        "id": "hLdud861gp-d",
        "outputId": "c43f8517-7c56-44b1-d361-2cda650cecce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (2024.11.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.13.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.2.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (3.1.6)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.10.2)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.6.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (4.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (75.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim->pyLDAvis) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->pyLDAvis) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim->pyLDAvis) (1.17.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.4\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Collecting scipy\n",
            "  Using cached scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy) (2.2.4)\n",
            "Using cached scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.4 which is incompatible.\n",
            "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scipy-1.15.2\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "Installing collected packages: numpy, scipy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.4\n",
            "    Uninstalling numpy-2.2.4:\n",
            "      Successfully uninstalled numpy-2.2.4\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.2\n",
            "    Uninstalling scipy-1.15.2:\n",
            "      Successfully uninstalled scipy-1.15.2\n",
            "Successfully installed numpy-1.26.4 scipy-1.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Subsets zusammenführen, Dopplungen entfernen"
      ],
      "metadata": {
        "id": "QHYGkuc0qYJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_data_raw = [r'/content/4_1_ergebnisse.csv', r'/content/4_2_ergebnisse.csv', r'/content/4_3_ergebnisse.csv', r'/content/4_4_ergebnisse.csv']\n",
        "\n",
        "csv_pfad = '/content/05_csv_data_raw.csv' # nicht wundern, hatte datei zwischenzeitlich umbenannt\n",
        "\n",
        "csv_no_doubles_pfad = '/content/06_data_raw_no_doubles.csv'\n",
        "\n",
        "df = pd.concat((pd.read_csv(f) for f in csv_data_raw), ignore_index=True)\n",
        "\n",
        "df.to_csv('csv_data_raw.csv', index=False)\n",
        "\n",
        "def entferne_doppelte_rezensionen(csv_pfad, anzahl_rezensionen=5):\n",
        "    df = pd.read_csv(csv_pfad)\n",
        "\n",
        "    # Doppelte Rezensionen basierend auf place_id und rezension entfernen\n",
        "    df = df.drop_duplicates(subset=['place_id', 'rezension'], keep='first')\n",
        "\n",
        "    # Anzahl der Rezensionen pro Ort begrenzen\n",
        "    df = df.groupby('place_id').head(anzahl_rezensionen).reset_index(drop=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Funktionsaufruf\n",
        "ergebnis_df = entferne_doppelte_rezensionen(csv_pfad)\n",
        "\n",
        "# Das bereinigte DataFrame anzeigen (optional)\n",
        "print(ergebnis_df)\n",
        "\n",
        "# Das bereinigte DataFrame in eine neue CSV-Datei speichern (optional)\n",
        "ergebnis_df.to_csv(\"06_data_raw_no_doubles.csv\", index=False)"
      ],
      "metadata": {
        "id": "Slx22u6-qeVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validierung der automatischen Abrufe: Zufallsstichprobe & manueller Abgleich"
      ],
      "metadata": {
        "id": "3kNZuQ7Ll3F3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(csv_no_doubles_pfad) #siehe oben\n",
        "\n",
        "def zufallsstichprobe(csv_pfad, stichprobengroesse=100, zufalls_seed=42): #seed 42\n",
        "    df = pd.read_csv(csv_no_doubles_pfad)\n",
        "\n",
        "    # Zufallsstichprobe ziehen\n",
        "    stichprobe_df = df.sample(n=min(stichprobengroesse, len(df)), random_state=zufalls_seed)\n",
        "\n",
        "    return stichprobe_df\n",
        "\n",
        "# Beispielaufruf:\n",
        "csv_datei = csv_no_doubles_pfad # Ersetzen Sie dies durch den tatsächlichen Dateinamen\n",
        "stichprobe = zufallsstichprobe(csv_datei, stichprobengroesse=100, zufalls_seed=42)\n",
        "\n",
        "# Die Stichprobe in eine neue CSV-Datei speichern (optional):\n",
        "stichprobe.to_csv(\"07_stichprobe_validierung.csv\", index=False)\n",
        "\n",
        "# Validierung manuell durchgeführt, für Kriterien siehe Hausarbeit;\n",
        "# Kodierung: 1 = valid; 0 = not valid or valid with restrictions;\n",
        "\n",
        "\n",
        "########## hier noch die Ergebnisse ausrechnen ###############"
      ],
      "metadata": {
        "id": "FijvKwsZl-Km",
        "outputId": "77c2fb07-3915-4c6e-b806-7d0bfbb8d10c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                     ort  \\\n",
            "2507   Alexius/Josef Krankenhaus, Montanusstraße 54, ...   \n",
            "11482  Sophien- und Hufeland-Klinikum gGmbH, Henry-va...   \n",
            "4207   Ev. Krankenhaus Lippstadt, Wiedenbrücker Straß...   \n",
            "1935   Rotes-Kreuz-Krankenhaus Bremen gGmbH, St.-Paul...   \n",
            "7768   Klinik Dr. Wilhelm, Hans-Urmiller-Ring 46, Wol...   \n",
            "...                                                  ...   \n",
            "10769  Hauptstandort Rudolf-Virchow-Klinikum, Virchow...   \n",
            "10563  Sana HANSE-Klinikum Wismar GmbH, Dr.-Unruh-Str...   \n",
            "8830   Bezirksklinikum Ansbach, Paracelsusstraße 36, ...   \n",
            "5006   Helios Kliniken Kassel, Hansteinstraße 29, Kassel   \n",
            "4216       LWL-Klinik Lippstadt, Im Hofholz 6, Lippstadt   \n",
            "\n",
            "                                        name                    strasze  \\\n",
            "2507               Alexius/Josef Krankenhaus             Montanusstraße   \n",
            "11482   Sophien- und Hufeland-Klinikum gGmbH  Henry-van-de-Velde-Straße   \n",
            "4207               Ev. Krankenhaus Lippstadt       Wiedenbrücker Straße   \n",
            "1935    Rotes-Kreuz-Krankenhaus Bremen gGmbH            St.-Pauli-Deich   \n",
            "7768                      Klinik Dr. Wilhelm         Hans-Urmiller-Ring   \n",
            "...                                      ...                        ...   \n",
            "10769  Hauptstandort Rudolf-Virchow-Klinikum                Virchowstr.   \n",
            "10563        Sana HANSE-Klinikum Wismar GmbH           Dr.-Unruh-Straße   \n",
            "8830                 Bezirksklinikum Ansbach           Paracelsusstraße   \n",
            "5006                  Helios Kliniken Kassel             Hansteinstraße   \n",
            "4216                    LWL-Klinik Lippstadt                 Im Hofholz   \n",
            "\n",
            "      hausnr                 stadt  bundesland                     place_id  \\\n",
            "2507      54          Grevenbroich         5.0  ChIJw7FzZxBMv0cRjlEgBW8E8q8   \n",
            "11482      2                Weimar        16.0  ChIJsXwo-S0FpEcRFkfrck38uL4   \n",
            "4207      33             Lippstadt         5.0  ChIJN-EgMv_Su0cR59EAVFIp7Og   \n",
            "1935     NaN                Bremen         4.0  ChIJh7ETvx4osUcRyTTKEulnwVw   \n",
            "7768      46        Wolfratshausen         9.0  ChIJzyXJjKPGnUcR6pbD81dI7JU   \n",
            "...      ...                   ...         ...                          ...   \n",
            "10769     18              Glauchau        14.0  ChIJ0a9ezKQvp0cR9LyxJpurJao   \n",
            "10563     14                Wismar        13.0  ChIJJzo-TVjHrUcRswybCjK0bIU   \n",
            "8830      36  Neustadt a. d. Aisch         9.0  ChIJn58c59kLokcRVMusIFGWHLw   \n",
            "5006      29                Kassel         6.0  ChIJtwosb2U_u0cRF_gesuG38XE   \n",
            "4216       6             Lippstadt         5.0  ChIJ_fI8VCTUu0cRnlWefvOgJPQ   \n",
            "\n",
            "       bewertung                                          rezension  \\\n",
            "2507           5  Bin die fünfte Woche in der Tagesklinik St. Au...   \n",
            "11482          5  Ich mußte eine OP in der Tagesklinik machen la...   \n",
            "4207           1  Leider wurde uns in der Notfallambulanz überha...   \n",
            "1935           5  Mein Vater wurde letzte Woche an der Hals-Ober...   \n",
            "7768           5  Ich war wegen einer OP durch meine Chirurgin i...   \n",
            "...          ...                                                ...   \n",
            "10769          5  Haben hier vor kurzem entbunden. Alles war top...   \n",
            "10563          1  Wer die Möglichkeit besitzt sollte dringend ei...   \n",
            "8830           5  Beste Einrichtung im Universum\\nAls Ich hier a...   \n",
            "5006           1  Mein Mann wurde morgens etwa um 10 Uhr aufgrun...   \n",
            "4216           5  Es war im Jahr 2020. Nichts ging mehr. Nicht g...   \n",
            "\n",
            "                       zeit  \n",
            "2507           vor 2 Jahren  \n",
            "11482          vor 3 Wochen  \n",
            "4207   in der letzten Woche  \n",
            "1935          vor 3 Monaten  \n",
            "7768        vor einem Monat  \n",
            "...                     ...  \n",
            "10769         vor 2 Monaten  \n",
            "10563       vor einer Woche  \n",
            "8830         vor 10 Monaten  \n",
            "5006        vor einem Monat  \n",
            "4216           vor 2 Jahren  \n",
            "\n",
            "[100 rows x 10 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "n_components bzw k festlegen"
      ],
      "metadata": {
        "id": "SNWhvh0aLyds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Daten laden und preprocessen (siehe vorherige Beispiele)\n",
        "\n",
        "# Define Parameter Grid\n",
        "param_grid = {'n_components': [2, 5, 10, 15]}\n",
        "\n",
        "# LDA Model\n",
        "lda = LatentDirichletAllocation(random_state=42)\n",
        "\n",
        "# Grid Search\n",
        "grid_search = GridSearchCV(lda, param_grid, scoring='neg_log_perplexity', cv=3)\n",
        "grid_search.fit(X)\n",
        "\n",
        "# Bestes Modell\n",
        "best_lda = grid_search.best_estimator_\n",
        "print(\"Beste Anzahl an Topics:\", grid_search.best_params_)"
      ],
      "metadata": {
        "id": "WINmnHnxL011",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "outputId": "91fd697f-51b1-40ab-cb98-308e58b0bd2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3257cd2b60cb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Grid Search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_log_perplexity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Bestes Modell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "xxxxxxxxxxxxxxx 3"
      ],
      "metadata": {
        "id": "Gs9EnmE8eE7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "import pyLDAvis.gensim_models\n",
        "import pyLDAvis\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', str(text))\n",
        "    text = text.lower()\n",
        "    tokens = text.split()\n",
        "    stop_words = set(stopwords.words('german'))\n",
        "    tokens = [token for token in tokens if token not in stop_words and len(token) > 2]\n",
        "    return tokens\n",
        "\n",
        "def prepare_corpus(processed_docs):\n",
        "    dictionary = corpora.Dictionary(processed_docs)\n",
        "    corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "    return dictionary, corpus\n",
        "\n",
        "def train_lda(corpus, dictionary, num_topics=5):\n",
        "    lda_model = LdaModel(corpus, num_topics=num_topics, id2word=dictionary, random_state=42)\n",
        "    return lda_model\n",
        "\n",
        "def evaluate_model(lda_model, corpus, dictionary, processed_docs):\n",
        "    coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_docs, dictionary=dictionary, coherence='c_v')\n",
        "    coherence = coherence_model_lda.get_coherence()\n",
        "    print('\\nCoherence Score: ', coherence)\n",
        "    return coherence\n",
        "\n",
        "def display_topics(lda_model, num_words=10):\n",
        "    for idx, topic in lda_model.print_topics(-1, num_words=num_words):\n",
        "        print(f'Topic: {idx} \\nWords: {topic}')\n",
        "\n",
        "def visualize_lda(lda_model, corpus, dictionary, filename=\"lda.html\"):\n",
        "    vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)\n",
        "    pyLDAvis.save_html(vis, filename) # Save as HTML\n",
        "    print(f\"LDA visualization saved to {filename}\")\n",
        "\n",
        "def main():\n",
        "    df = pd.read_csv(r'/content/06_data_raw_no_doubles.csv')\n",
        "    review_column = 'rezension'\n",
        "    rating_column = 'bewertung'\n",
        "\n",
        "    if review_column not in df.columns or rating_column not in df.columns:\n",
        "        raise ValueError(f\"Column '{review_column}' or '{rating_column}' not found in DataFrame.\")\n",
        "\n",
        "    positive_df = df[df[rating_column] >= 4]\n",
        "    negative_df = df[df[rating_column] <= 2]\n",
        "\n",
        "    print(\"Starte LDA für positive Bewertungen:\")\n",
        "    positive_reviews = positive_df[review_column].astype(str)\n",
        "    processed_positive = positive_reviews.map(preprocess_text)\n",
        "    dictionary_positive, corpus_positive = prepare_corpus(processed_positive)\n",
        "\n",
        "    num_topics_positive = 5\n",
        "    lda_model_positive = train_lda(corpus_positive, dictionary_positive, num_topics=num_topics_positive)\n",
        "    coherence_score_positive = evaluate_model(lda_model_positive, corpus_positive, dictionary_positive,processed_positive)\n",
        "    display_topics(lda_model_positive)\n",
        "    visualize_lda(lda_model_positive, corpus_positive, dictionary_positive, \"lda_positive.html\")\n",
        "\n",
        "    print(\"\\nStarte LDA für negative Bewertungen:\")\n",
        "    negative_reviews = negative_df[review_column].astype(str)\n",
        "    processed_negative = negative_reviews.map(preprocess_text)\n",
        "    dictionary_negative, corpus_negative = prepare_corpus(processed_negative)\n",
        "\n",
        "    num_topics_negative = 5\n",
        "    lda_model_negative = train_lda(corpus_negative, dictionary_negative, num_topics=num_topics_negative)\n",
        "    coherence_score_negative = evaluate_model(lda_model_negative, corpus_negative, dictionary_negative,processed_negative)\n",
        "    display_topics(lda_model_negative)\n",
        "    visualize_lda(lda_model_negative, corpus_negative, dictionary_negative, \"lda_negative.html\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "WdBic6xneHRd",
        "outputId": "59f5341c-bdfa-40e6-86ae-e9aab3cc7601",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starte LDA für positive Bewertungen:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Coherence Score:  0.40011651397111986\n",
            "Topic: 0 \n",
            "Words: 0.019*\"gut\" + 0.016*\"wurde\" + 0.012*\"freundlich\" + 0.011*\"station\" + 0.010*\"dank\" + 0.009*\"krankenhaus\" + 0.009*\"ärzte\" + 0.008*\"personal\" + 0.008*\"klinik\" + 0.008*\"super\"\n",
            "Topic: 1 \n",
            "Words: 0.007*\"nan\" + 0.006*\"tagesklinik\" + 0.005*\"gut\" + 0.005*\"klinik\" + 0.004*\"super\" + 0.004*\"patienten\" + 0.004*\"zeit\" + 0.004*\"immer\" + 0.004*\"freundlich\" + 0.004*\"danke\"\n",
            "Topic: 2 \n",
            "Words: 0.020*\"klinik\" + 0.012*\"team\" + 0.011*\"gut\" + 0.011*\"wurde\" + 0.008*\"dank\" + 0.007*\"freundlich\" + 0.006*\"zeit\" + 0.006*\"danke\" + 0.006*\"vielen\" + 0.005*\"ärzte\"\n",
            "Topic: 3 \n",
            "Words: 0.014*\"immer\" + 0.011*\"klinik\" + 0.008*\"gut\" + 0.008*\"essen\" + 0.008*\"gibt\" + 0.007*\"patienten\" + 0.006*\"freundlich\" + 0.005*\"zeit\" + 0.005*\"zimmer\" + 0.005*\"mal\"\n",
            "Topic: 4 \n",
            "Words: 0.009*\"dank\" + 0.009*\"möchte\" + 0.007*\"betreuung\" + 0.006*\"zeit\" + 0.006*\"geburt\" + 0.006*\"frau\" + 0.005*\"team\" + 0.005*\"gut\" + 0.005*\"vielen\" + 0.005*\"patienten\"\n",
            "LDA visualization saved to lda_positive.html\n",
            "\n",
            "Starte LDA für negative Bewertungen:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Coherence Score:  0.2859322586973052\n",
            "Topic: 0 \n",
            "Words: 0.016*\"wurde\" + 0.007*\"leider\" + 0.006*\"mehr\" + 0.006*\"klinik\" + 0.005*\"mal\" + 0.005*\"stunden\" + 0.004*\"einfach\" + 0.004*\"krankenhaus\" + 0.004*\"station\" + 0.003*\"tag\"\n",
            "Topic: 1 \n",
            "Words: 0.015*\"patienten\" + 0.010*\"klinik\" + 0.009*\"wurde\" + 0.006*\"arzt\" + 0.005*\"mehr\" + 0.005*\"mal\" + 0.005*\"einfach\" + 0.005*\"menschen\" + 0.005*\"ärzte\" + 0.004*\"krankenhaus\"\n",
            "Topic: 2 \n",
            "Words: 0.012*\"wurde\" + 0.008*\"krankenhaus\" + 0.006*\"mehr\" + 0.006*\"termin\" + 0.005*\"patienten\" + 0.004*\"uhr\" + 0.004*\"stunden\" + 0.004*\"warten\" + 0.004*\"notaufnahme\" + 0.004*\"arzt\"\n",
            "Topic: 3 \n",
            "Words: 0.015*\"wurde\" + 0.009*\"klinik\" + 0.008*\"mal\" + 0.006*\"notaufnahme\" + 0.005*\"leider\" + 0.005*\"mutter\" + 0.005*\"mehr\" + 0.005*\"patienten\" + 0.005*\"schon\" + 0.004*\"arzt\"\n",
            "Topic: 4 \n",
            "Words: 0.016*\"wurde\" + 0.009*\"krankenhaus\" + 0.006*\"station\" + 0.005*\"patienten\" + 0.005*\"notaufnahme\" + 0.005*\"einfach\" + 0.004*\"arzt\" + 0.004*\"mal\" + 0.004*\"tag\" + 0.004*\"mehr\"\n",
            "LDA visualization saved to lda_negative.html\n"
          ]
        }
      ]
    }
  ]
}